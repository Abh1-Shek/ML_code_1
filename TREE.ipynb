{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "# 8019\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, condition, children, decisions):\n",
    "        self.condition = condition\n",
    "        self.children = children\n",
    "        self.decisions = decisions\n",
    "        \n",
    "class Leaf:\n",
    "    def __init__(self, leaf_value):\n",
    "        self.leaf_value = leaf_value\n",
    "        self.condition = \"THIS IS A LEAF NODE!!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, dataset = None, THRESHOLD_VALUE = 0.0, THRESHOLD_SIZE = 10, IS_CATEGORICAL = [0,0,0,0,0,0,0,0,0,0,0], TARGET_COLUMN = \"new_cases_classes\", Tree_Type = \"entropy\", THRESHOLD_FOR_ACCURACY = 1):\n",
    "        # this cell contains all the constants please beware\n",
    "        self.THRESHOLD_VALUE = THRESHOLD_VALUE\n",
    "        self.THRESHOLD_SIZE = THRESHOLD_SIZE\n",
    "        self.IS_CATEGORICAL = IS_CATEGORICAL\n",
    "        self.TARGET_COLUMN = TARGET_COLUMN\n",
    "        self.dataset = dataset\n",
    "        self.Tree_Type = Tree_Type\n",
    "        self.THRESHOLD_FOR_ACCURACY = THRESHOLD_FOR_ACCURACY\n",
    "        self.root = self.build_tree(self.dataset)\n",
    "        \n",
    "    \n",
    "    def set_dataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    # helper function for getting probability from frequency table\n",
    "    # this function is used in get_entropy()\n",
    "    def get_probability(self, event_info):\n",
    "        SUM = sum(event_info)\n",
    "        for i in range(len(event_info)):\n",
    "                event_info[i] /= SUM\n",
    "        return event_info\n",
    "\n",
    "\n",
    "    # this function gets entropy from frequency table\n",
    "    def get_entropy(self, event_info):\n",
    "        probabilities = self.get_probability(event_info)\n",
    "        # print('probabilities', probabilities)\n",
    "        entropy = 0.0\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                entropy += p * math.log(1 / p) / math.log(2)\n",
    "        return entropy\n",
    "\n",
    "    # this function gets gini impurity from frequency table\n",
    "    def get_gini_impurity(self, event_info):\n",
    "        probabilities = self.get_probability(event_info)\n",
    "        # print('probabilities', probabilities)\n",
    "        imp = 0.0\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                imp += p * (1.0 - p)\n",
    "        return imp\n",
    "   \n",
    "    #this funtion sort table by column\n",
    "    def sort_table_by_column(self, table, col):\n",
    "        return table.sort_values(by = [col]).reset_index(drop=True)\n",
    "   \n",
    "    def split_dataset_wrt_column(self, dataset, column_name):\n",
    "        unique_items = dataset[column_name].unique()\n",
    "        tables = []\n",
    "        for item in unique_items:\n",
    "            tables.append(dataset[dataset[column_name] == item])\n",
    "        return tables\n",
    "    def get_count(self, table, target_column, class_name):\n",
    "        # print(class_name)\n",
    "        # ans =  (table[target_column] == class_name).shape[0]\n",
    "        ans = (table[target_column] == class_name).sum()\n",
    "        # print (ans)\n",
    "        return ans\n",
    "    def get_entropy_from_table(self, table, target_column):\n",
    "        unique_classes = table[target_column].unique()\n",
    "        # print(unique_classes)\n",
    "        counts = []\n",
    "        for class_name in unique_classes:\n",
    "            counts.append(self.get_count(table,target_column, class_name))\n",
    "        # print(\"Count is \", counts)\n",
    "        if self.Tree_Type == \"entropy\":\n",
    "            return self.get_entropy(counts)\n",
    "        else:\n",
    "            return self.get_gini_impurity(counts)    # write get_gini_impurity if you want to change the parameter to gini imp from entropy\n",
    "    # this function returns the information gain of the column \"column\" when the target column is \"target_column\" of the table dataset\n",
    "    # only for categorical column or attribute\n",
    "    def get_information_gain(self, dataset, column, target_column):\n",
    "        tables = []\n",
    "        size_table = []\n",
    "        overall_size = dataset.shape[0]\n",
    "        for table in self.split_dataset_wrt_column(dataset, column):\n",
    "            tables.append(table)\n",
    "            size_table.append(table.shape[0])\n",
    "        entropies = []\n",
    "        for table in tables:\n",
    "            # print(table)\n",
    "            entropies.append(self.get_entropy_from_table(table, target_column))\n",
    "        # print(\"entropies=\", entropies)\n",
    "        # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
    "        # print(entropies)\n",
    "        entropy_initial = self.get_entropy_from_table(dataset, target_column)    # entropy without splitting\n",
    "        # print(\"entropy_intial=\",entropy_initial)\n",
    "        entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(size_table, entropies)])  # entropy after splitting\n",
    "        return (entropy_initial - entropy)\n",
    "\n",
    "    def max_index(self, arr):\n",
    "        index = 0\n",
    "        mx = arr[0]\n",
    "        for i in range(len(arr)):\n",
    "            if mx < arr[i]:\n",
    "                index = i\n",
    "                mx = arr[i]\n",
    "        return index\n",
    "    def get_value_with_min_entropy_wrt_continuous_column(self, table, column, target_column):\n",
    "        # step 1: sort the table\n",
    "        new_table = self.sort_table_by_column(table, column)\n",
    "        # print(new_table)\n",
    "        # step 2: get various averages\n",
    "        avg_array = []\n",
    "        length_new_table = len(new_table)\n",
    "        for i in range(length_new_table - 1):\n",
    "            avg_array.append((new_table.at[i,column] + new_table.at[i + 1, column]) / 2)\n",
    "        \n",
    "        # print(avg_array)\n",
    "        # step 3: count before and after averages\n",
    "        IGs = []\n",
    "        parentIG = self.get_entropy_from_table(new_table, target_column)\n",
    "        for i in range(length_new_table - 1):\n",
    "            table1 = new_table.iloc[:i + 1,:]\n",
    "            table2 = new_table.iloc[i + 1:, :]\n",
    "            # print('Table 1')\n",
    "            # print(table1)\n",
    "            # print('Table 2')\n",
    "            # print(table2)\n",
    "            E1 = self.get_entropy_from_table(table1, target_column)\n",
    "            E2 = self.get_entropy_from_table(table2, target_column)\n",
    "            # print('E1=',E1, 'E2=', E2)\n",
    "            E = (len(table1) / len(table)) * E1 + (len(table2) / len(table)) * E2\n",
    "            IG = parentIG - E\n",
    "            IGs.append(IG)\n",
    "        # print(IGs)\n",
    "        # if(len(avg_array) == 0):\n",
    "        #     IGs = [0]\n",
    "        #     avg_array = [1]\n",
    "        index = self.max_index(IGs)\n",
    "        \n",
    "        return avg_array[index], IGs[index]  # split wrt value, IG according to that value\n",
    "        # step 4: calculate the entropy wrt each average\n",
    "        # step 5: determine the best split with most information gain\n",
    "        #This function returns the best column for the split\n",
    "    def get_best_column (self, table, target_column, is_categorical):\n",
    "        values = []\n",
    "        # is_categorical is an array which is true if the data is categorical and false if continuous\n",
    "        IGs = []\n",
    "        for index,column in enumerate(table):\n",
    "            if(column == target_column):\n",
    "                break\n",
    "            # print(column,index)\n",
    "            if(is_categorical[index] == 1):\n",
    "                values.append(None)\n",
    "                IGs.append(self.get_information_gain(table, column, target_column))\n",
    "            else:\n",
    "                #value is the value at which the splitting occurs in the column and IG is the corresponding Info gain\n",
    "                value, IG = self.get_value_with_min_entropy_wrt_continuous_column(table,column,target_column)\n",
    "                values.append(value)\n",
    "                # print(value)\n",
    "                IGs.append(IG)\n",
    "        selected_index = self.max_index(IGs)\n",
    "        if(is_categorical[selected_index]):\n",
    "            return selected_index, table.columns[selected_index], None, IGs[selected_index]\n",
    "        else:\n",
    "            return selected_index, table.columns[selected_index],values[selected_index], IGs[selected_index]\n",
    "    def split_table_wrt_value(self, table,value,column):\n",
    "        table1 = table[table[column] <= value]\n",
    "        table2 = table[table[column] > value]\n",
    "        return table1,table2\n",
    "\n",
    "    # returns the value and probability for the leaf which have maximum probability\n",
    "    def get_value_for_leaf(self, table, target_column):\n",
    "        freq = dict()\n",
    "        unique_classes = table[target_column].unique()\n",
    "        for class_name in unique_classes:\n",
    "            freq[class_name] = 0\n",
    "        for index, row in table.iterrows():\n",
    "            freq[row[target_column]] += 1\n",
    "        mx = 0\n",
    "        value = None\n",
    "        sum_of_freq = 0.0\n",
    "        for class_name, freq_of_class in freq.items():\n",
    "            sum_of_freq += freq_of_class\n",
    "            if mx < freq_of_class:\n",
    "                mx = freq_of_class\n",
    "                value = class_name\n",
    "        return value, mx / sum_of_freq\n",
    "    \n",
    "    def build_tree(self, table, height = 0):\n",
    "        # print(\"height =\", height, \"shape =\", table.shape)\n",
    "        if table.shape[1] == 1 or len(table) <= self.THRESHOLD_SIZE:\n",
    "            return Leaf(self.get_value_for_leaf(table, self.TARGET_COLUMN))\n",
    "        # step1 find the best split\n",
    "        selected_index, column_name, value, best_IG = self.get_best_column(table, self.TARGET_COLUMN, self.IS_CATEGORICAL)\n",
    "        tables = []\n",
    "        decisions = []\n",
    "        condition = None\n",
    "        # categorical value\n",
    "        if value == None:\n",
    "            tables = self.split_dataset_wrt_column(table, column_name)\n",
    "            start_index = 0\n",
    "            for splited_table in tables:\n",
    "                decisions.append(splited_table.iloc[0][column_name])\n",
    "                start_index += len(splited_table)\n",
    "            condition = [None, column_name]\n",
    "        # Continuous Value\n",
    "        else:\n",
    "            table1, table2 = self.split_table_wrt_value(table, value, column_name)\n",
    "            table1 = table1.drop([column_name], axis = 1)\n",
    "            table2 = table2.drop([column_name], axis = 1)\n",
    "            if len(table1) > 0: \n",
    "                tables.append(table1)\n",
    "            if len(table2) > 0:\n",
    "                tables.append(table2)\n",
    "            decisions = [None,None]\n",
    "            condition = [value, column_name]\n",
    "        # put some base condition\n",
    "        if best_IG <= self.THRESHOLD_VALUE or len(table) <= self.THRESHOLD_SIZE:\n",
    "            return Leaf(self.get_value_for_leaf(table, self.TARGET_COLUMN))\n",
    "        # make tree for each child\n",
    "        children = []\n",
    "        for table in tables:\n",
    "            if len(table) > 0:\n",
    "                child = self.build_tree(table, height + 1)\n",
    "                children.append(child)\n",
    "        # return the current node which is already linked to its children so that current node's parent can link current node\n",
    "        return Node(condition, children,decisions)\n",
    "    \n",
    "    def print_tree(self, root, spacing=\"\"):\n",
    "        if isinstance(root, Leaf):\n",
    "            print(spacing, root.leaf_value)\n",
    "            return\n",
    "        print(spacing, root.condition,root.decisions)\n",
    "        for child in root.children:\n",
    "            self.print_tree(child,spacing+\"--> \")\n",
    "    def print_decision_tree(self):\n",
    "        self.print_tree(self.root)\n",
    "    \n",
    "    def find_index(self, arr,x):\n",
    "        for i in range (len(arr)):\n",
    "            if(arr[i] == x):\n",
    "                return i\n",
    "    def predict_util(self, row,root, starting_index = 0):\n",
    "        #base case\n",
    "        # print(row)\n",
    "        if(isinstance(root,Leaf)):\n",
    "            return root.leaf_value\n",
    "        value_to_check = row.at[starting_index, root.condition[1]]\n",
    "        if root.condition[0] != None:\n",
    "            split_value = root.condition[0]\n",
    "            if value_to_check <= split_value:\n",
    "                child_index = 0\n",
    "            else:\n",
    "                child_index = 1\n",
    "        else:\n",
    "            child_index = self.find_index(root.decisions, value_to_check)\n",
    "        # print(value_to_check, root.decisions)\n",
    "        return self.predict_util(row, root.children[child_index], starting_index)\n",
    "\n",
    "        \n",
    "    def predict_for_table(self, table, root):\n",
    "        predictions = []\n",
    "        for index, row in table.iterrows():\n",
    "            row = row.to_frame().T\n",
    "            # print(\"index =\", index)\n",
    "            # print('predictions =', predict(row, root, index))\n",
    "            predictions.append(self.predict_util(row, root, index))\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.predict_for_table(data, self.root)\n",
    "    \n",
    "    def calculate_accuracy(self, testing_data):\n",
    "        predictions = self.predict(testing_data)\n",
    "        score = 0\n",
    "        DIFF = 0.0\n",
    "        THRESHOLD_FOR_ACCURACY = 1\n",
    "        for i in range(len(testing_data)):\n",
    "            actual = testing_data.at[i, self.TARGET_COLUMN]\n",
    "            predicted = predictions[i]\n",
    "            # print(actual, predicted)\n",
    "            DIFF += abs(actual - predicted[0])\n",
    "            score += (abs(actual - predicted[0]) <= self.THRESHOLD_FOR_ACCURACY)\n",
    "\n",
    "        print(score / len(testing_data) * 100)\n",
    "        return predictions, DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stringency_index         float64\n",
      "new_deaths               float64\n",
      "retail_and_recreation    float64\n",
      "grocery_and_pharmacy     float64\n",
      "residential              float64\n",
      "transit_stations         float64\n",
      "parks                    float64\n",
      "workplaces               float64\n",
      "day                        int64\n",
      "month                      int64\n",
      "year                       int64\n",
      "new_cases_classes        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset5 = pd.read_csv(r'processed_covid_data.csv') # for running on pc use only filename as path, /content/sample_data/\n",
    "print(dataset5.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stringency_index</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>retail_and_recreation</th>\n",
       "      <th>grocery_and_pharmacy</th>\n",
       "      <th>residential</th>\n",
       "      <th>transit_stations</th>\n",
       "      <th>parks</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>new_cases_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.571</td>\n",
       "      <td>0.286</td>\n",
       "      <td>2.286</td>\n",
       "      <td>-2.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>-5.429</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.857</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.286</td>\n",
       "      <td>-2.571</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-6.143</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.429</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>2.286</td>\n",
       "      <td>-3.286</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-6.857</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>-1.429</td>\n",
       "      <td>2.857</td>\n",
       "      <td>-5.143</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-8.714</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.857</td>\n",
       "      <td>-2.857</td>\n",
       "      <td>3.286</td>\n",
       "      <td>-6.571</td>\n",
       "      <td>-1.714</td>\n",
       "      <td>-9.286</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>81.94</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>-62.143</td>\n",
       "      <td>-25.429</td>\n",
       "      <td>24.429</td>\n",
       "      <td>-49.429</td>\n",
       "      <td>-41.857</td>\n",
       "      <td>-46.000</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>81.94</td>\n",
       "      <td>3617.0</td>\n",
       "      <td>-61.714</td>\n",
       "      <td>-25.000</td>\n",
       "      <td>24.143</td>\n",
       "      <td>-49.143</td>\n",
       "      <td>-41.000</td>\n",
       "      <td>-45.429</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>81.94</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>-61.286</td>\n",
       "      <td>-24.429</td>\n",
       "      <td>23.714</td>\n",
       "      <td>-48.714</td>\n",
       "      <td>-40.000</td>\n",
       "      <td>-44.571</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>81.94</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>-61.143</td>\n",
       "      <td>-24.714</td>\n",
       "      <td>23.714</td>\n",
       "      <td>-49.000</td>\n",
       "      <td>-39.143</td>\n",
       "      <td>-44.286</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>81.94</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>-60.143</td>\n",
       "      <td>-23.429</td>\n",
       "      <td>23.286</td>\n",
       "      <td>-48.286</td>\n",
       "      <td>-38.000</td>\n",
       "      <td>-43.429</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stringency_index  new_deaths  retail_and_recreation  \\\n",
       "0               26.85         1.0                 -3.571   \n",
       "1               26.85         0.0                 -3.857   \n",
       "2               33.33         1.0                 -4.429   \n",
       "3               36.11         0.0                 -6.000   \n",
       "4               38.89         0.0                 -7.857   \n",
       "..                ...         ...                    ...   \n",
       "442             81.94      3660.0                -62.143   \n",
       "443             81.94      3617.0                -61.714   \n",
       "444             81.94      3460.0                -61.286   \n",
       "445             81.94      3128.0                -61.143   \n",
       "446             81.94      2795.0                -60.143   \n",
       "\n",
       "     grocery_and_pharmacy  residential  transit_stations   parks  workplaces  \\\n",
       "0                   0.286        2.286            -2.286   0.714      -5.429   \n",
       "1                   0.000        2.286            -2.571   0.571      -6.143   \n",
       "2                  -0.143        2.286            -3.286   0.571      -6.857   \n",
       "3                  -1.429        2.857            -5.143  -0.571      -8.714   \n",
       "4                  -2.857        3.286            -6.571  -1.714      -9.286   \n",
       "..                    ...          ...               ...     ...         ...   \n",
       "442               -25.429       24.429           -49.429 -41.857     -46.000   \n",
       "443               -25.000       24.143           -49.143 -41.000     -45.429   \n",
       "444               -24.429       23.714           -48.714 -40.000     -44.571   \n",
       "445               -24.714       23.714           -49.000 -39.143     -44.286   \n",
       "446               -23.429       23.286           -48.286 -38.000     -43.429   \n",
       "\n",
       "     day  month  year  new_cases_classes  \n",
       "0      3     11  2020                0.0  \n",
       "1      3     12  2020                0.0  \n",
       "2     13      3  2020                0.0  \n",
       "3     14      3  2020                0.0  \n",
       "4     15      3  2020                0.0  \n",
       "..   ...    ...   ...                ...  \n",
       "442   27      5  2021              186.0  \n",
       "443   28      5  2021              173.0  \n",
       "444   29      5  2021              165.0  \n",
       "445   30      5  2021              152.0  \n",
       "446   31      5  2021              127.0  \n",
       "\n",
       "[447 rows x 12 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset5.sample(frac = 0.7)\n",
    "testing_data = dataset5.drop(training_data.index)\n",
    "training_data.reset_index(drop=True, inplace=True)\n",
    "testing_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_ID3A = DecisionTree(dataset=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [437.5, 'new_deaths'] [None, None]\n",
      "-->  [-10.357, 'grocery_and_pharmacy'] [None, None]\n",
      "--> -->  [84.255, 'stringency_index'] [None, None]\n",
      "--> --> -->  [-76.5, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> -->  (3.0, 0.7777777777777778)\n",
      "--> --> --> -->  (6.0, 0.4)\n",
      "--> --> -->  [-78.4285, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> -->  [4.0, 'month'] [None, None]\n",
      "--> --> --> --> -->  [28.3575, 'residential'] [None, None]\n",
      "--> --> --> --> --> -->  (2.0, 1.0)\n",
      "--> --> --> --> --> -->  [2020.0, 'year'] [None, None]\n",
      "--> --> --> --> --> --> -->  [-66.2145, 'transit_stations'] [None, None]\n",
      "--> --> --> --> --> --> --> -->  (1.0, 0.8)\n",
      "--> --> --> --> --> --> --> -->  (1.0, 1.0)\n",
      "--> --> --> -->  [-54.0, 'parks'] [None, None]\n",
      "--> --> --> --> -->  (7.0, 0.5)\n",
      "--> --> --> --> -->  [4.0, 'day'] [None, None]\n",
      "--> --> --> --> --> -->  (0.0, 0.8571428571428571)\n",
      "--> --> --> --> --> -->  (0.0, 1.0)\n",
      "--> -->  [-13.0, 'workplaces'] [None, None]\n",
      "--> --> -->  [11.0, 'month'] [None, None]\n",
      "--> --> --> -->  [61.57, 'stringency_index'] [None, None]\n",
      "--> --> --> --> -->  [-10.785499999999999, 'parks'] [None, None]\n",
      "--> --> --> --> --> -->  [19.0, 'day'] [None, None]\n",
      "--> --> --> --> --> --> -->  [9.0, 'residential'] [None, None]\n",
      "--> --> --> --> --> --> --> -->  [2021.0, 'year'] [None, None]\n",
      "--> --> --> --> --> --> --> --> -->  [-25.357, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> --> --> --> --> --> --> -->  (12.0, 0.6)\n",
      "--> --> --> --> --> --> --> --> --> -->  (11.0, 0.5)\n",
      "--> --> --> --> --> --> --> -->  (8.0, 1.0)\n",
      "--> --> --> --> --> --> -->  (11.0, 0.2857142857142857)\n",
      "--> --> --> --> --> -->  (13.0, 0.2222222222222222)\n",
      "--> --> --> --> -->  [-58.286, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> --> --> -->  [7.0, 'day'] [None, None]\n",
      "--> --> --> --> --> --> -->  (10.0, 0.5)\n",
      "--> --> --> --> --> --> -->  (19.0, 0.25)\n",
      "--> --> --> --> --> -->  [-14.785499999999999, 'transit_stations'] [None, None]\n",
      "--> --> --> --> --> --> -->  (14.0, 0.2222222222222222)\n",
      "--> --> --> --> --> --> -->  [-14.286000000000001, 'parks'] [None, None]\n",
      "--> --> --> --> --> --> --> -->  (18.0, 0.6666666666666666)\n",
      "--> --> --> --> --> --> --> -->  (16.0, 0.5)\n",
      "--> --> --> -->  [11.714, 'residential'] [None, None]\n",
      "--> --> --> --> -->  [2020.0, 'year'] [None, None]\n",
      "--> --> --> --> --> -->  [68.98, 'stringency_index'] [None, None]\n",
      "--> --> --> --> --> --> -->  [-26.9285, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> --> --> --> --> -->  [-9.713999999999999, 'transit_stations'] [None, None]\n",
      "--> --> --> --> --> --> --> --> -->  (25.0, 0.3333333333333333)\n",
      "--> --> --> --> --> --> --> --> -->  (24.0, 0.375)\n",
      "--> --> --> --> --> --> --> -->  (22.0, 0.25)\n",
      "--> --> --> --> --> -->  (12.0, 0.5)\n",
      "--> --> --> --> -->  (11.0, 0.5)\n",
      "--> --> -->  [7.286, 'residential'] [None, None]\n",
      "--> --> --> -->  [-18.2145, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> --> -->  (18.0, 0.4)\n",
      "--> --> --> --> -->  (0.0, 1.0)\n",
      "--> --> --> -->  (17.0, 0.1)\n",
      "-->  [2020.0, 'year'] [None, None]\n",
      "--> -->  [-3.357, 'grocery_and_pharmacy'] [None, None]\n",
      "--> --> -->  [-51.0715, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> -->  [-51.286, 'parks'] [None, None]\n",
      "--> --> --> --> -->  [87.5, 'stringency_index'] [None, None]\n",
      "--> --> --> --> --> -->  [16.2145, 'residential'] [None, None]\n",
      "--> --> --> --> --> --> -->  (64.0, 0.2857142857142857)\n",
      "--> --> --> --> --> --> -->  (37.0, 0.2857142857142857)\n",
      "--> --> --> --> -->  [-31.643, 'workplaces'] [None, None]\n",
      "--> --> --> --> --> -->  (52.0, 0.42857142857142855)\n",
      "--> --> --> --> --> -->  (22.0, 0.25)\n",
      "--> --> --> -->  [-49.357, 'parks'] [None, None]\n",
      "--> --> --> --> -->  [85.65, 'stringency_index'] [None, None]\n",
      "--> --> --> --> --> -->  [8.0, 'month'] [None, None]\n",
      "--> --> --> --> --> --> -->  [12.857, 'residential'] [None, None]\n",
      "--> --> --> --> --> --> --> -->  (78.0, 0.25)\n",
      "--> --> --> --> --> --> --> -->  (69.0, 0.6666666666666666)\n",
      "--> --> --> --> -->  [-30.714, 'transit_stations'] [None, None]\n",
      "--> --> --> --> --> -->  [85.65, 'stringency_index'] [None, None]\n",
      "--> --> --> --> --> --> -->  [-25.143, 'workplaces'] [None, None]\n",
      "--> --> --> --> --> --> --> -->  (83.0, 0.6666666666666666)\n",
      "--> --> --> --> --> --> --> -->  [13.214500000000001, 'residential'] [None, None]\n",
      "--> --> --> --> --> --> --> --> -->  (90.0, 0.3333333333333333)\n",
      "--> --> --> --> --> --> --> --> -->  (75.0, 0.5)\n",
      "--> --> --> --> --> -->  (82.0, 0.2)\n",
      "--> --> -->  [-31.214, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> -->  [-43.9285, 'parks'] [None, None]\n",
      "--> --> --> --> -->  (74.0, 0.25)\n",
      "--> --> --> --> -->  (55.0, 0.2222222222222222)\n",
      "--> --> --> -->  [10.286, 'residential'] [None, None]\n",
      "--> --> --> --> -->  [11.0, 'month'] [None, None]\n",
      "--> --> --> --> --> -->  [-17.3575, 'transit_stations'] [None, None]\n",
      "--> --> --> --> --> --> -->  (48.0, 0.2)\n",
      "--> --> --> --> --> --> -->  (44.0, 0.75)\n",
      "--> --> --> --> --> -->  (44.0, 1.0)\n",
      "--> --> --> --> -->  [-38.5, 'parks'] [None, None]\n",
      "--> --> --> --> --> -->  (50.0, 0.6)\n",
      "--> --> --> --> --> -->  (45.0, 0.5)\n",
      "--> -->  [5.0, 'month'] [None, None]\n",
      "--> --> -->  [19.0, 'day'] [None, None]\n",
      "--> --> --> -->  [73.61, 'stringency_index'] [None, None]\n",
      "--> --> --> --> -->  [-35.5715, 'retail_and_recreation'] [None, None]\n",
      "--> --> --> --> --> -->  (259.0, 0.2)\n",
      "--> --> --> --> --> -->  (37.0, 0.16666666666666666)\n",
      "--> --> --> --> -->  (343.0, 0.1111111111111111)\n",
      "--> --> --> -->  [77.775, 'stringency_index'] [None, None]\n",
      "--> --> --> --> -->  (352.0, 0.1)\n",
      "--> --> --> --> -->  (127.0, 0.1)\n",
      "--> --> -->  (168.0, 0.125)\n"
     ]
    }
   ],
   "source": [
    "DT_ID3A.print_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.641791044776117\n",
      "R1 = 2612.0\n"
     ]
    }
   ],
   "source": [
    "predictions, R1 = DT_ID3A.calculate_accuracy(testing_data=testing_data)\n",
    "print(\"R1 =\", R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual = testing_data[DT_ID3A.TARGET_COLUMN].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pi, ai in zip(predictions, actual):\n",
    "#     print(pi[0], ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_CART = DecisionTree(dataset=training_data, Tree_Type = \"CART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.65671641791045\n",
      "R1 = 1921.0\n"
     ]
    }
   ],
   "source": [
    "predictions, R1 = DT_CART.calculate_accuracy(testing_data=testing_data)\n",
    "print('R1 =', R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ae141d93f6337e9a20a8395b8018e64e99a1e5c84b295f1c46fe5520871454d"
  },
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
