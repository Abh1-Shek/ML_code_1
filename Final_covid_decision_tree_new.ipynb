{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jSMWxblgZIUO"
      },
      "outputs": [],
      "source": [
        "# importing packages\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "olU2Ae2vZIUb"
      },
      "outputs": [],
      "source": [
        "# helper function for getting probability from frequency table\n",
        "# this function is used in get_entropy()\n",
        "def get_probability(event_info):\n",
        "  SUM = sum(event_info)\n",
        "  for i in range(len(event_info)):\n",
        "        event_info[i] /= SUM\n",
        "  return event_info\n",
        "\n",
        "\n",
        "# this function gets entropy from frequency table\n",
        "def get_entropy(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  # print('probabilities', probabilities)\n",
        "  entropy = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      entropy += p * math.log(1 / p) / math.log(2)\n",
        "  return entropy\n",
        "\n",
        "# this function gets gini impurity from frequency table\n",
        "def get_gini_impurity(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  # print('probabilities', probabilities)\n",
        "  imp = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      imp += p * (1.0 - p)\n",
        "  return imp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z067x_bdZIUe"
      },
      "outputs": [],
      "source": [
        "#this funtion sort table by column\n",
        "def sort_table_by_column(table, col):\n",
        "    return table.sort_values(by = [col]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f9UNYlRcFSYT"
      },
      "outputs": [],
      "source": [
        "# # for importing the dataset as a numpy array\n",
        "# dataset1 = pd.read_csv(r\"covid_dataset.csv\")\n",
        "# dataset1 = dataset1[dataset1['location'] == 'India']\n",
        "# # dataset1 = dataset1.to_numpy()\n",
        "# dataset2 = pd.read_csv(r\"changes-visitors-covid.csv\")\n",
        "# dataset2 = dataset2[dataset2['Entity'] == 'India']\n",
        "# # dataset2 = dataset2.to_numpy()\n",
        "# dataset3 = pd.read_csv(r'continuous_attribute_table.csv')\n",
        "# dataset4 = pd.read_csv(r'pure_category.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jc9hI-LmFSYT"
      },
      "outputs": [],
      "source": [
        "# dataset = pd.merge(dataset1, dataset2, on = 'date', how = 'inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X2ZxAmij0lYN"
      },
      "outputs": [],
      "source": [
        "# example_dataset = dataset1 = pd.read_csv(r\"example_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KfXU0JpnZIUr"
      },
      "outputs": [],
      "source": [
        "# print(example_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "14rFwiubcfP1"
      },
      "outputs": [],
      "source": [
        "def split_dataset_wrt_column(dataset, column_name):\n",
        "  unique_items = dataset[column_name].unique()\n",
        "  tables = []\n",
        "  for item in unique_items:\n",
        "    tables.append(dataset[dataset[column_name] == item])\n",
        "  return tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WT5mBi9bitUH"
      },
      "outputs": [],
      "source": [
        "def get_count(table, target_column, class_name):\n",
        "  # print(class_name)\n",
        "  # ans =  (table[target_column] == class_name).shape[0]\n",
        "  ans = (table[target_column] == class_name).sum()\n",
        "  # print (ans)\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_GkSt7uXhvQu"
      },
      "outputs": [],
      "source": [
        "def get_entropy_from_table(table, target_column):\n",
        "  unique_classes = table[target_column].unique()\n",
        "  # print(unique_classes)\n",
        "  counts = []\n",
        "  for class_name in unique_classes:\n",
        "    counts.append(get_count(table,target_column, class_name))\n",
        "  # print(\"Count is \", counts)\n",
        "  return get_entropy(counts)    # write get_gini_impurity if you want to change the parameter to gini imp from entropy\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0GeFnIU6gGeC"
      },
      "outputs": [],
      "source": [
        "# this function returns the information gain of the column \"column\" when the target column is \"target_column\" of the table dataset\n",
        "# only for categorical column or attribute\n",
        "def get_information_gain(dataset, column, target_column):\n",
        "  tables = []\n",
        "  size_table = []\n",
        "  overall_size = dataset.shape[0]\n",
        "  for table in split_dataset_wrt_column(dataset, column):\n",
        "    tables.append(table)\n",
        "    size_table.append(table.shape[0])\n",
        "  entropies = []\n",
        "  for table in tables:\n",
        "    # print(table)\n",
        "    entropies.append(get_entropy_from_table(table, target_column))\n",
        "  # print(\"entropies=\", entropies)\n",
        "  # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
        "  # print(entropies)\n",
        "  entropy_initial = get_entropy_from_table(dataset, target_column)    # entropy without splitting\n",
        "  # print(\"entropy_intial=\",entropy_initial)\n",
        "  entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(size_table, entropies)])  # entropy after splitting\n",
        "  return (entropy_initial - entropy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nwdChokGjfGR"
      },
      "outputs": [],
      "source": [
        "# get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y7BKcqQbFSYX"
      },
      "outputs": [],
      "source": [
        "def max_index(arr):\n",
        "    index = 0\n",
        "    mx = arr[0]\n",
        "    for i in range(len(arr)):\n",
        "        if mx < arr[i]:\n",
        "            index = i\n",
        "            mx = arr[i]\n",
        "    return index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EWxhZSY7nRQL"
      },
      "outputs": [],
      "source": [
        "# get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bWlzydeJFSYY"
      },
      "outputs": [],
      "source": [
        "def get_value_with_min_entropy_wrt_continuous_column(table, column, target_column):\n",
        "    # step 1: sort the table\n",
        "    new_table = sort_table_by_column(table, column)\n",
        "    # print(new_table)\n",
        "    # step 2: get various averages\n",
        "    avg_array = []\n",
        "    length_new_table = len(new_table)\n",
        "    for i in range(length_new_table - 1):\n",
        "        avg_array.append((new_table.at[i,column] + new_table.at[i + 1, column]) / 2)\n",
        "    \n",
        "    # print(avg_array)\n",
        "    # step 3: count before and after averages\n",
        "    IGs = []\n",
        "    parentIG = get_entropy_from_table(new_table, target_column)\n",
        "    for i in range(length_new_table - 1):\n",
        "        table1 = new_table.iloc[:i + 1,:]\n",
        "        table2 = new_table.iloc[i + 1:, :]\n",
        "        # print('Table 1')\n",
        "        # print(table1)\n",
        "        # print('Table 2')\n",
        "        # print(table2)\n",
        "        E1 = get_entropy_from_table(table1, target_column)\n",
        "        E2 = get_entropy_from_table(table2, target_column)\n",
        "        # print('E1=',E1, 'E2=', E2)\n",
        "        E = (len(table1) / len(table)) * E1 + (len(table2) / len(table)) * E2\n",
        "        IG = parentIG - E\n",
        "        IGs.append(IG)\n",
        "    # print(IGs)\n",
        "    # if(len(avg_array) == 0):\n",
        "    #     IGs = [0]\n",
        "    #     avg_array = [1]\n",
        "    index = max_index(IGs)\n",
        "    \n",
        "    return avg_array[index], IGs[index]  # split wrt value, IG according to that value\n",
        "    # step 4: calculate the entropy wrt each average\n",
        "    # step 5: determine the best split with most information gain\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XP7f8Pe9FSYY"
      },
      "outputs": [],
      "source": [
        "# get_value_with_min_entropy_wrt_continuous_column(dataset3, 'Weight', 'Heart_disease')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5gc6u622FSYY"
      },
      "outputs": [],
      "source": [
        "# dataset3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nA5vGyQBFSYZ"
      },
      "outputs": [],
      "source": [
        "#This function returns the best column for the split\n",
        "def get_best_column (table, target_column, is_categorical):\n",
        "    values = []\n",
        "    # is_categorical is an array which is true if the data is categorical and false if continuous\n",
        "    IGs = []\n",
        "    for index,column in enumerate(table):\n",
        "        if(column == target_column):\n",
        "            break\n",
        "        # print(column,index)\n",
        "        if(is_categorical[index] == 1):\n",
        "            values.append(None)\n",
        "            IGs.append(get_information_gain(table, column, target_column))\n",
        "        else:\n",
        "            #value is the value at which the splitting occurs in the column and IG is the corresponding Info gain\n",
        "            value, IG = get_value_with_min_entropy_wrt_continuous_column(table,column,target_column)\n",
        "            values.append(value)\n",
        "            # print(value)\n",
        "            IGs.append(IG)\n",
        "    selected_index = max_index(IGs)\n",
        "    if(is_categorical[selected_index]):\n",
        "        return selected_index, table.columns[selected_index], None, IGs[selected_index]\n",
        "    else:\n",
        "        return selected_index, table.columns[selected_index],values[selected_index], IGs[selected_index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3JOCYodiFSYZ"
      },
      "outputs": [],
      "source": [
        "# get_best_column(example_dataset, 'target', [1,0,1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u69sS8y4FSYZ"
      },
      "outputs": [],
      "source": [
        "def split_table_wrt_value(table,value,column):\n",
        "    table1 = table[table[column] <= value]\n",
        "    table2 = table[table[column] > value]\n",
        "    return table1,table2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "klKLuVJRFSYZ"
      },
      "outputs": [],
      "source": [
        "# table1, table2 = split_table_wrt_value(example_dataset,56.0,'Value')\n",
        "# print(table1)\n",
        "# print()\n",
        "# print(table2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5MjvHwtjFSYZ"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, condition, children, decisions):\n",
        "        self.condition = condition\n",
        "        self.children = children\n",
        "        self.decisions = decisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pSp04j8DFSYa"
      },
      "outputs": [],
      "source": [
        "class Leaf:\n",
        "    def __init__(self, leaf_value):\n",
        "        self.leaf_value = leaf_value\n",
        "        self.condition = \"THIS IS A LEAF NODE!!\"\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K5KRACpHFSYa"
      },
      "outputs": [],
      "source": [
        "# this cell contains all the constants please beware\n",
        "THRESHOLD_VALUE = 0.0\n",
        "THRESHOLD_SIZE = 10\n",
        "IS_CATEGORICAL = [0, 0, 0, 0, 0, 0]\n",
        "TARGET_COLUMN = \"new_cases_classes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "y0KzxcvwFSYa"
      },
      "outputs": [],
      "source": [
        "# returns the value and probability for the leaf which have maximum probability\n",
        "def get_value_for_leaf(table, target_column):\n",
        "    freq = dict()\n",
        "    unique_classes = table[target_column].unique()\n",
        "    for class_name in unique_classes:\n",
        "        freq[class_name] = 0\n",
        "    for index, row in table.iterrows():\n",
        "        freq[row[target_column]] += 1\n",
        "    mx = 0\n",
        "    value = None\n",
        "    sum_of_freq = 0.0\n",
        "    for class_name, freq_of_class in freq.items():\n",
        "        sum_of_freq += freq_of_class\n",
        "        if mx < freq_of_class:\n",
        "            mx = freq_of_class\n",
        "            value = class_name\n",
        "    return value, mx / sum_of_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "x4B23UrpFSYa"
      },
      "outputs": [],
      "source": [
        "def build_tree(table):\n",
        "    if len(table) <= THRESHOLD_SIZE:\n",
        "      return Leaf(get_value_for_leaf(table, TARGET_COLUMN))\n",
        "    # step1 find the best split\n",
        "    selected_index, column_name, value, best_IG = get_best_column(table, TARGET_COLUMN, IS_CATEGORICAL)\n",
        "    tables = []\n",
        "    decisions = []\n",
        "    condition = None\n",
        "    # categorical value\n",
        "    if value == None:\n",
        "        tables = split_dataset_wrt_column(table, column_name)\n",
        "        start_index = 0\n",
        "        for splited_table in tables:\n",
        "            decisions.append(splited_table.iloc[0][column_name])\n",
        "            start_index += len(splited_table)\n",
        "        condition = [None, column_name]\n",
        "    # Continuous Value\n",
        "    else:\n",
        "        table1, table2 = split_table_wrt_value(table, value, column_name)\n",
        "        tables.append(table1)\n",
        "        tables.append(table2)\n",
        "        decisions = [None,None]\n",
        "        condition = [value, column_name]\n",
        "    # put some base condition\n",
        "    if best_IG <= THRESHOLD_VALUE or len(table) <= THRESHOLD_SIZE:\n",
        "        return Leaf(get_value_for_leaf(table, TARGET_COLUMN))\n",
        "    # make tree for each child\n",
        "    children = []\n",
        "    for table in tables:\n",
        "        child = build_tree(table)\n",
        "        children.append(child)\n",
        "    # return the current node which is already linked to its children so that current node's parent can link current node\n",
        "    return Node(condition, children,decisions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gLivJepMFSYa"
      },
      "outputs": [],
      "source": [
        "# root = build_tree(example_dataset) # before running this cell change the IS_CATEGORICAL array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-ONHzJHeFSYb"
      },
      "outputs": [],
      "source": [
        "# print(root.condition)\n",
        "# for child in root.children:\n",
        "#     print(child.condition)\n",
        "#     if (child.condition == \"THIS IS A LEAF NODE!!\"):\n",
        "#         print(child.leaf_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sJXYiykJFSYb"
      },
      "outputs": [],
      "source": [
        "# root = build_tree(dataset4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mpyJvF6pFSYb"
      },
      "outputs": [],
      "source": [
        "# print(root.condition)\n",
        "# for child in root.children:\n",
        "#     print(child.condition)\n",
        "#     if (child.condition == \"THIS IS A LEAF NODE!!\"):\n",
        "#         print(child.leaf_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BbQy2f9GFSYb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def print_tree(root, spacing=\"\"):\n",
        "    if isinstance(root, Leaf):\n",
        "        print(spacing, root.leaf_value)\n",
        "        return\n",
        "    print(spacing, root.condition,root.decisions)\n",
        "    for child in root.children:\n",
        "        print_tree(child,spacing+\"--> \")\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-kdK1F_KFSYb"
      },
      "outputs": [],
      "source": [
        "# print_tree(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eARfuDRWFSYb"
      },
      "outputs": [],
      "source": [
        "def find_index(arr,x):\n",
        "    for i in range (len(arr)):\n",
        "        if(arr[i] == x):\n",
        "            return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0kb9QqY_FSYb"
      },
      "outputs": [],
      "source": [
        "def predict(row,root, starting_index = 0):\n",
        "    #base case\n",
        "    # print(row)\n",
        "    if(isinstance(root,Leaf)):\n",
        "        return root.leaf_value\n",
        "    value_to_check = row.at[starting_index, root.condition[1]]\n",
        "    if root.condition[0] != None:\n",
        "        split_value = root.condition[0]\n",
        "        if value_to_check <= split_value:\n",
        "            child_index = 0\n",
        "        else:\n",
        "            child_index = 1\n",
        "    else:\n",
        "        child_index = find_index(root.decisions, value_to_check)\n",
        "    # print(value_to_check, root.decisions)\n",
        "    return predict(row, root.children[child_index], starting_index)\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WheRs2PSFSYb"
      },
      "outputs": [],
      "source": [
        "# test_data = pd.DataFrame({\n",
        "#     'Outlook': ['rainy'],\n",
        "#     'Company': ['big'],\n",
        "#     'Sailboat': ['small']\n",
        "# })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bnlP-NXLFSYc"
      },
      "outputs": [],
      "source": [
        "# print(predict(test_data, root))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwoOcI-dFSYc",
        "outputId": "d92fa73a-161f-4989-aa8e-b1bfd17ed1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "retail_and_recreation    float64\n",
            "grocery_and_pharmacy     float64\n",
            "residential              float64\n",
            "transit_stations         float64\n",
            "parks                    float64\n",
            "workplaces               float64\n",
            "new_cases_classes          int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "dataset5 = pd.read_csv(r'processed_covid_data.csv') # for running on pc use only filename as path, /content/sample_data/\n",
        "print(dataset5.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7I2UeUU2FSYc",
        "outputId": "473197fa-5d2f-4f4c-f01d-d7ca77137403"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>retail_and_recreation</th>\n",
              "      <th>grocery_and_pharmacy</th>\n",
              "      <th>residential</th>\n",
              "      <th>transit_stations</th>\n",
              "      <th>parks</th>\n",
              "      <th>workplaces</th>\n",
              "      <th>new_cases_classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.667</td>\n",
              "      <td>1.667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.750</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.250</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.400</td>\n",
              "      <td>1.800</td>\n",
              "      <td>0.200</td>\n",
              "      <td>1.800</td>\n",
              "      <td>2.800</td>\n",
              "      <td>3.200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.500</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.333</td>\n",
              "      <td>3.167</td>\n",
              "      <td>3.333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.143</td>\n",
              "      <td>1.714</td>\n",
              "      <td>0.714</td>\n",
              "      <td>1.429</td>\n",
              "      <td>3.571</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>-61.714</td>\n",
              "      <td>-25.000</td>\n",
              "      <td>24.143</td>\n",
              "      <td>-49.143</td>\n",
              "      <td>-41.000</td>\n",
              "      <td>-45.429</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>-61.286</td>\n",
              "      <td>-24.429</td>\n",
              "      <td>23.714</td>\n",
              "      <td>-48.714</td>\n",
              "      <td>-40.000</td>\n",
              "      <td>-44.571</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>-61.143</td>\n",
              "      <td>-24.714</td>\n",
              "      <td>23.714</td>\n",
              "      <td>-49.000</td>\n",
              "      <td>-39.143</td>\n",
              "      <td>-44.286</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>-60.143</td>\n",
              "      <td>-23.429</td>\n",
              "      <td>23.286</td>\n",
              "      <td>-48.286</td>\n",
              "      <td>-38.000</td>\n",
              "      <td>-43.429</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>-58.714</td>\n",
              "      <td>-21.143</td>\n",
              "      <td>22.714</td>\n",
              "      <td>-47.000</td>\n",
              "      <td>-36.571</td>\n",
              "      <td>-42.429</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>471 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     retail_and_recreation  grocery_and_pharmacy  residential  \\\n",
              "0                    0.667                 1.667        0.000   \n",
              "1                    0.500                 1.750        0.000   \n",
              "2                    0.400                 1.800        0.200   \n",
              "3                    0.500                 2.000        0.000   \n",
              "4                   -0.143                 1.714        0.714   \n",
              "..                     ...                   ...          ...   \n",
              "466                -61.714               -25.000       24.143   \n",
              "467                -61.286               -24.429       23.714   \n",
              "468                -61.143               -24.714       23.714   \n",
              "469                -60.143               -23.429       23.286   \n",
              "470                -58.714               -21.143       22.714   \n",
              "\n",
              "     transit_stations   parks  workplaces  new_cases_classes  \n",
              "0               2.000   3.000       3.000                  0  \n",
              "1               2.000   3.250       3.000                  0  \n",
              "2               1.800   2.800       3.200                  0  \n",
              "3               2.333   3.167       3.333                  0  \n",
              "4               1.429   3.571       0.143                  0  \n",
              "..                ...     ...         ...                ...  \n",
              "466           -49.143 -41.000     -45.429                200  \n",
              "467           -48.714 -40.000     -44.571                200  \n",
              "468           -49.000 -39.143     -44.286                201  \n",
              "469           -48.286 -38.000     -43.429                206  \n",
              "470           -47.000 -36.571     -42.429                207  \n",
              "\n",
              "[471 rows x 7 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qqA7Vf48FSYc"
      },
      "outputs": [],
      "source": [
        "# root = build_tree(dataset5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA2mCqocFSYc",
        "outputId": "31141bf9-45d0-43f3-af4e-3724528dfa13"
      },
      "outputs": [],
      "source": [
        "# print_tree(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLKgHiQqFSYc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GYr67y7LFSYd"
      },
      "outputs": [],
      "source": [
        "training_data = dataset5.sample(frac = 0.7)\n",
        "testing_data = dataset5.drop(training_data.index)\n",
        "training_data.reset_index(drop=True, inplace=True)\n",
        "testing_data.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(47, 7)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "testing_data.shape\n",
        "root = build_tree(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_for_table(table, root):\n",
        "    predictions = []\n",
        "    for index, row in table.iterrows():\n",
        "        row = row.to_frame().T\n",
        "        # print(\"index =\", index)\n",
        "        # print('predictions =', predict(row, root, index))\n",
        "        predictions.append(predict(row, root, index))\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = predict_for_table(testing_data, root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30.424528301886795\n"
          ]
        }
      ],
      "source": [
        "score = 0\n",
        "THRESHOLD_FOR_ACCURACY = 1\n",
        "for i in range(len(testing_data)):\n",
        "    actual = testing_data.at[i, TARGET_COLUMN]\n",
        "    predicted = predictions[i]\n",
        "    # print(actual, predicted)\n",
        "    score += (abs(actual - predicted[0]) <= THRESHOLD_FOR_ACCURACY)\n",
        "\n",
        "print(score / len(testing_data) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_lab_1_example.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4ae141d93f6337e9a20a8395b8018e64e99a1e5c84b295f1c46fe5520871454d"
    },
    "kernelspec": {
      "display_name": "'Python Interactive'",
      "language": "python",
      "name": "52c418bc-bd7d-4061-b6a2-3b59f32782e1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
