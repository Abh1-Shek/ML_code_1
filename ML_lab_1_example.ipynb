{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "jSMWxblgZIUO"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "olU2Ae2vZIUb"
      },
      "outputs": [],
      "source": [
        "def get_probability(event_info):\n",
        "  SUM = sum(event_info)\n",
        "  for i in range(len(event_info)):\n",
        "        event_info[i] /= SUM\n",
        "  return event_info\n",
        "\n",
        "\n",
        "def get_entropy(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  entropy = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      entropy += p * math.log(1 / p) / math.log(2)\n",
        "  return entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "z067x_bdZIUe"
      },
      "outputs": [],
      "source": [
        "def sort_table_by_column(table, col):\n",
        "    return table[table[:, col].argsort()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for importing the dataset as a numpy array\n",
        "dataset1 = pd.read_csv(r\"covid_dataset.csv\")\n",
        "dataset1 = dataset1[dataset1['location'] == 'India']\n",
        "# dataset1 = dataset1.to_numpy()\n",
        "dataset2 = pd.read_csv(r\"changes-visitors-covid.csv\")\n",
        "dataset2 = dataset2[dataset2['Entity'] == 'India']\n",
        "# dataset2 = dataset2.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.merge(dataset1, dataset2, on = 'date', how = 'inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "X2ZxAmij0lYN"
      },
      "outputs": [],
      "source": [
        "example_dataset = dataset1 = pd.read_csv(r\"example_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfXU0JpnZIUr",
        "outputId": "8028e3e2-181a-4fb8-9586-342564df58c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Outlook Company Sailboat target\n",
            "0   sunny     big    small    yes\n",
            "1   sunny     med    small    yes\n",
            "2   sunny     med      big    yes\n",
            "3   sunny      no    small    yes\n",
            "4   sunny     big      big    yes\n",
            "5   rainy      no    small     no\n",
            "6   rainy     med    small    yes\n",
            "7   rainy     big      big    yes\n",
            "8   rainy      no      big     no\n",
            "9   rainy     med      big     no\n"
          ]
        }
      ],
      "source": [
        "print(example_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "14rFwiubcfP1"
      },
      "outputs": [],
      "source": [
        "def split_dataset_wrt_column(dataset, column_name):\n",
        "  unique_items = dataset[column_name].unique()\n",
        "  for item in unique_items:\n",
        "    yield dataset[dataset[column_name] == item]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "eWLqeR9qekVY"
      },
      "outputs": [],
      "source": [
        "class node:\n",
        "  def __init__(self):\n",
        "    self.table = None\n",
        "    self.spliting_feature = None\n",
        "    self.childs = []\n",
        "  def add_child(self, child):\n",
        "    self.childs.append(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "WT5mBi9bitUH"
      },
      "outputs": [],
      "source": [
        "def get_count(table, target_column, class_name):\n",
        "  # print(class_name)\n",
        "  # ans =  (table[target_column] == class_name).shape[0]\n",
        "  ans = (table[target_column] == class_name).sum()\n",
        "  # print (ans)\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "_GkSt7uXhvQu"
      },
      "outputs": [],
      "source": [
        "def get_entropy_from_table(table, target_column):\n",
        "  unique_classes = table[target_column].unique()\n",
        "  # print(unique_classes)\n",
        "  counts = []\n",
        "  for class_name in unique_classes:\n",
        "    counts.append(get_count(table,target_column, class_name))\n",
        "  # print(\"Count is \", counts)\n",
        "  return get_entropy(counts)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "0GeFnIU6gGeC"
      },
      "outputs": [],
      "source": [
        "def get_information_gain(dataset, column, target_column):\n",
        "  tables = []\n",
        "  size_table = []\n",
        "  overall_size = dataset.shape[0]\n",
        "  for table in split_dataset_wrt_column(dataset, column):\n",
        "    tables.append(table)\n",
        "    size_table.append(table.shape[0])\n",
        "  entropies = []\n",
        "  for table in tables:\n",
        "    # print(table)\n",
        "    entropies.append(get_entropy_from_table(table, target_column))\n",
        "  print(entropies)\n",
        "  # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
        "  # print(entropies)\n",
        "  # entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(sizes, entropies)])\n",
        "  # return entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "nwdChokGjfGR",
        "outputId": "8cd86971-c26a-4981-bdf6-a8cf0b382329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7219280948873624, 0.9709505944546688]\n"
          ]
        }
      ],
      "source": [
        "get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWxhZSY7nRQL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_lab_1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4ae141d93f6337e9a20a8395b8018e64e99a1e5c84b295f1c46fe5520871454d"
    },
    "kernelspec": {
      "display_name": "'Python Interactive'",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
