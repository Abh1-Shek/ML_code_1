{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1188,
      "metadata": {
        "id": "jSMWxblgZIUO"
      },
      "outputs": [],
      "source": [
        "# importing packages\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1189,
      "metadata": {
        "id": "olU2Ae2vZIUb"
      },
      "outputs": [],
      "source": [
        "# helper function for getting probability from frequency table\n",
        "# this function is used in get_entropy()\n",
        "def get_probability(event_info):\n",
        "  SUM = sum(event_info)\n",
        "  for i in range(len(event_info)):\n",
        "        event_info[i] /= SUM\n",
        "  return event_info\n",
        "\n",
        "\n",
        "# this function gets entropy from frequency table\n",
        "def get_entropy(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  # print('probabilities', probabilities)\n",
        "  entropy = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      entropy += p * math.log(1 / p) / math.log(2)\n",
        "  return entropy\n",
        "\n",
        "# this function gets gini impurity from frequency table\n",
        "def get_gini_impurity(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  # print('probabilities', probabilities)\n",
        "  imp = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      imp += p * (1.0 - p)\n",
        "  return imp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1190,
      "metadata": {
        "id": "z067x_bdZIUe"
      },
      "outputs": [],
      "source": [
        "#this funtion sort table by column\n",
        "def sort_table_by_column(table, col):\n",
        "    return table.sort_values(by = [col]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1191,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for importing the dataset as a numpy array\n",
        "dataset1 = pd.read_csv(r\"covid_dataset.csv\")\n",
        "dataset1 = dataset1[dataset1['location'] == 'India']\n",
        "# dataset1 = dataset1.to_numpy()\n",
        "dataset2 = pd.read_csv(r\"changes-visitors-covid.csv\")\n",
        "dataset2 = dataset2[dataset2['Entity'] == 'India']\n",
        "# dataset2 = dataset2.to_numpy()\n",
        "dataset3 = pd.read_csv(r'continuous_attribute_table.csv')\n",
        "dataset4 = pd.read_csv(r'pure_category.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1192,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.merge(dataset1, dataset2, on = 'date', how = 'inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1193,
      "metadata": {
        "id": "X2ZxAmij0lYN"
      },
      "outputs": [],
      "source": [
        "example_dataset = dataset1 = pd.read_csv(r\"example_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfXU0JpnZIUr",
        "outputId": "8028e3e2-181a-4fb8-9586-342564df58c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Outlook  Value Company Sailboat target\n",
            "0   sunny    100     big    small    yes\n",
            "1   sunny    200     med    small    yes\n",
            "2   sunny    300     med      big    yes\n",
            "3   sunny    400      no    small    yes\n",
            "4   sunny    500     big      big    yes\n",
            "5   rainy     10      no    small     no\n",
            "6   rainy    500     med    small    yes\n",
            "7   rainy    510     big      big    yes\n",
            "8   rainy     12      no      big     no\n",
            "9   rainy      9     med      big     no\n"
          ]
        }
      ],
      "source": [
        "print(example_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1195,
      "metadata": {
        "id": "14rFwiubcfP1"
      },
      "outputs": [],
      "source": [
        "def split_dataset_wrt_column(dataset, column_name):\n",
        "  unique_items = dataset[column_name].unique()\n",
        "  tables = []\n",
        "  for item in unique_items:\n",
        "    tables.append(dataset[dataset[column_name] == item])\n",
        "  return tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1196,
      "metadata": {
        "id": "WT5mBi9bitUH"
      },
      "outputs": [],
      "source": [
        "def get_count(table, target_column, class_name):\n",
        "  # print(class_name)\n",
        "  # ans =  (table[target_column] == class_name).shape[0]\n",
        "  ans = (table[target_column] == class_name).sum()\n",
        "  # print (ans)\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1197,
      "metadata": {
        "id": "_GkSt7uXhvQu"
      },
      "outputs": [],
      "source": [
        "def get_entropy_from_table(table, target_column):\n",
        "  unique_classes = table[target_column].unique()\n",
        "  # print(unique_classes)\n",
        "  counts = []\n",
        "  for class_name in unique_classes:\n",
        "    counts.append(get_count(table,target_column, class_name))\n",
        "  # print(\"Count is \", counts)\n",
        "  return get_entropy(counts)    # write get_gini_impurity if you want to change the parameter to gini imp from entropy\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1198,
      "metadata": {
        "id": "0GeFnIU6gGeC"
      },
      "outputs": [],
      "source": [
        "# this function returns the information gain of the column \"column\" when the target column is \"target_column\" of the table dataset\n",
        "# only for categorical column or attribute\n",
        "def get_information_gain(dataset, column, target_column):\n",
        "  tables = []\n",
        "  size_table = []\n",
        "  overall_size = dataset.shape[0]\n",
        "  for table in split_dataset_wrt_column(dataset, column):\n",
        "    tables.append(table)\n",
        "    size_table.append(table.shape[0])\n",
        "  entropies = []\n",
        "  for table in tables:\n",
        "    # print(table)\n",
        "    entropies.append(get_entropy_from_table(table, target_column))\n",
        "  # print(\"entropies=\", entropies)\n",
        "  # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
        "  # print(entropies)\n",
        "  entropy_initial = get_entropy_from_table(dataset, target_column)    # entropy without splitting\n",
        "  # print(\"entropy_intial=\",entropy_initial)\n",
        "  entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(size_table, entropies)])  # entropy after splitting\n",
        "  return (entropy_initial - entropy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "nwdChokGjfGR",
        "outputId": "8cd86971-c26a-4981-bdf6-a8cf0b382329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.034851554559677034"
            ]
          },
          "execution_count": 1199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1200,
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_index(arr):\n",
        "    index = 0\n",
        "    mx = arr[0]\n",
        "    for i in range(len(arr)):\n",
        "        if mx < arr[i]:\n",
        "            index = i\n",
        "            mx = arr[i]\n",
        "    return index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1201,
      "metadata": {
        "id": "EWxhZSY7nRQL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.034851554559677034"
            ]
          },
          "execution_count": 1201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1202,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_value_with_min_entropy_wrt_continuous_column(table, column, target_column):\n",
        "    # step 1: sort the table\n",
        "    new_table = sort_table_by_column(table, column)\n",
        "    # print(new_table)\n",
        "    # step 2: get various averages\n",
        "    avg_array = []\n",
        "    length_new_table = len(new_table)\n",
        "    for i in range(length_new_table - 1):\n",
        "        avg_array.append((new_table.at[i,column] + new_table.at[i + 1, column]) / 2)\n",
        "    \n",
        "    # print(avg_array)\n",
        "    # step 3: count before and after averages\n",
        "    IGs = []\n",
        "    parentIG = get_entropy_from_table(new_table, target_column)\n",
        "    for i in range(length_new_table - 1):\n",
        "        table1 = new_table.iloc[:i + 1,:]\n",
        "        table2 = new_table.iloc[i + 1:, :]\n",
        "        # print('Table 1')\n",
        "        # print(table1)\n",
        "        # print('Table 2')\n",
        "        # print(table2)\n",
        "        E1 = get_entropy_from_table(table1, target_column)\n",
        "        E2 = get_entropy_from_table(table2, target_column)\n",
        "        # print('E1=',E1, 'E2=', E2)\n",
        "        E = (len(table1) / len(table)) * E1 + (len(table2) / len(table)) * E2\n",
        "        IG = parentIG - E\n",
        "        IGs.append(IG)\n",
        "    # print(IGs)\n",
        "    index = max_index(IGs)\n",
        "    \n",
        "    return avg_array[index], IGs[index]  # split wrt value, IG according to that value\n",
        "    # step 4: calculate the entropy wrt each average\n",
        "    # step 5: determine the best split with most information gain\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1203,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(205.0, 0.41997309402197514)"
            ]
          },
          "execution_count": 1203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_value_with_min_entropy_wrt_continuous_column(dataset3, 'Weight', 'Heart_disease')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Heart_disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>225</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>180</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weight Heart_disease\n",
              "0     155            No\n",
              "1     190            No\n",
              "2     220           Yes\n",
              "3     225           Yes\n",
              "4     180           Yes"
            ]
          },
          "execution_count": 1204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1205,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function returns the best column for the split\n",
        "def get_best_column (table, target_column, is_categorical):\n",
        "    values = []\n",
        "    # is_categorical is an array which is true if the data is categorical and false if continuous\n",
        "    IGs = []\n",
        "    for index,column in enumerate(table):\n",
        "        if(column == target_column):\n",
        "            break\n",
        "        # print(column,index)\n",
        "        if(is_categorical[index] == 1):\n",
        "            values.append(None)\n",
        "            IGs.append(get_information_gain(table, column, target_column))\n",
        "        else:\n",
        "            #value is the value at which the splitting occurs in the column and IG is the corresponding Info gain\n",
        "            value, IG = get_value_with_min_entropy_wrt_continuous_column(table,column,target_column)\n",
        "            values.append(value)\n",
        "            # print(value)\n",
        "            IGs.append(IG)\n",
        "    selected_index = max_index(IGs)\n",
        "    if(is_categorical[selected_index]):\n",
        "        return selected_index, table.columns[selected_index], None, IGs[selected_index]\n",
        "    else:\n",
        "        return selected_index, table.columns[selected_index],values[selected_index], IGs[selected_index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1206,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 'Value', 56.0, 0.8812908992306927)"
            ]
          },
          "execution_count": 1206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_best_column(example_dataset, 'target', [1,0,1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1207,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_table_wrt_value(table,value,column):\n",
        "    table1 = table[table[column] <= value]\n",
        "    table2 = table[table[column] > value]\n",
        "    return table1,table2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1208,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Outlook  Value Company Sailboat target\n",
            "5   rainy     10      no    small     no\n",
            "8   rainy     12      no      big     no\n",
            "9   rainy      9     med      big     no\n",
            "\n",
            "  Outlook  Value Company Sailboat target\n",
            "0   sunny    100     big    small    yes\n",
            "1   sunny    200     med    small    yes\n",
            "2   sunny    300     med      big    yes\n",
            "3   sunny    400      no    small    yes\n",
            "4   sunny    500     big      big    yes\n",
            "6   rainy    500     med    small    yes\n",
            "7   rainy    510     big      big    yes\n"
          ]
        }
      ],
      "source": [
        "table1, table2 = split_table_wrt_value(example_dataset,56.0,'Value')\n",
        "print(table1)\n",
        "print()\n",
        "print(table2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1209,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, condition, children, decisions):\n",
        "        self.condition = condition\n",
        "        self.children = children\n",
        "        self.decisions = decisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1210,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Leaf:\n",
        "    def __init__(self, leaf_value):\n",
        "        self.leaf_value = leaf_value\n",
        "        self.condition = \"THIS IS A LEAF NODE!!\"\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1211,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this cell contains all the constants please beware\n",
        "THRESHOLD_VALUE = 0.0\n",
        "IS_CATEGORICAL = [1, 1, 1]\n",
        "TARGET_COLUMN = \"target\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1212,
      "metadata": {},
      "outputs": [],
      "source": [
        "# returns the value and probability for the leaf which have maximum probability\n",
        "def get_value_for_leaf(table, target_column):\n",
        "    freq = dict()\n",
        "    unique_classes = table[target_column].unique()\n",
        "    for class_name in unique_classes:\n",
        "        freq[class_name] = 0\n",
        "    for index, row in table.iterrows():\n",
        "        freq[row[target_column]] += 1\n",
        "    mx = 0\n",
        "    value = None\n",
        "    sum_of_freq = 0.0\n",
        "    for class_name, freq_of_class in freq.items():\n",
        "        sum_of_freq += freq_of_class\n",
        "        if mx < freq_of_class:\n",
        "            mx = freq_of_class\n",
        "            value = class_name\n",
        "    return value, mx / sum_of_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1228,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_tree(table):\n",
        "    # step1 find the best split\n",
        "    selected_index, column_name, value, best_IG = get_best_column(table, TARGET_COLUMN, IS_CATEGORICAL)\n",
        "    tables = []\n",
        "    decisions = []\n",
        "    condition = None\n",
        "    # categorical value\n",
        "    if value == None:\n",
        "        tables = split_dataset_wrt_column(table, column_name)\n",
        "        start_index = 0\n",
        "        for splited_table in tables:\n",
        "            decisions.append(splited_table.iloc[0][column_name])\n",
        "            start_index += len(splited_table)\n",
        "        condition = column_name\n",
        "    # Continuous Value\n",
        "    else:\n",
        "        table1, table2 = split_table_wrt_value(table, value, column_name)\n",
        "        tables.append(table1)\n",
        "        tables.append(table2)\n",
        "        decisions = [None,None]\n",
        "        condition = [value, column_name]\n",
        "    # put some base condition\n",
        "    if best_IG <= THRESHOLD_VALUE:\n",
        "        return Leaf(get_value_for_leaf(table, TARGET_COLUMN))\n",
        "    # make tree for each child\n",
        "    children = []\n",
        "    for table in tables:\n",
        "        child = build_tree(table)\n",
        "        children.append(child)\n",
        "    # return the current node which is already linked to its children so that current node's parent can link current node\n",
        "    return Node(condition, children,decisions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1229,
      "metadata": {},
      "outputs": [],
      "source": [
        "# root = build_tree(example_dataset) # before running this cell change the IS_CATEGORICAL array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1230,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlook\n",
            "THIS IS A LEAF NODE!!\n",
            "('yes', 1.0)\n",
            "Company\n"
          ]
        }
      ],
      "source": [
        "print(root.condition)\n",
        "for child in root.children:\n",
        "    print(child.condition)\n",
        "    if (child.condition == \"THIS IS A LEAF NODE!!\"):\n",
        "        print(child.leaf_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1231,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = build_tree(dataset4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlook\n",
            "THIS IS A LEAF NODE!!\n",
            "('yes', 1.0)\n",
            "Company\n"
          ]
        }
      ],
      "source": [
        "print(root.condition)\n",
        "for child in root.children:\n",
        "    print(child.condition)\n",
        "    if (child.condition == \"THIS IS A LEAF NODE!!\"):\n",
        "        print(child.leaf_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1238,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def print_tree(root, spacing=\"\"):\n",
        "    if isinstance(root, Leaf):\n",
        "        print(spacing, root.leaf_value)\n",
        "        return\n",
        "    print(spacing, root.condition,root.decisions)\n",
        "    for child in root.children:\n",
        "        print_tree(child,spacing+\"--> \")\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Outlook ['sunny', 'rainy']\n",
            "-->  ('yes', 1.0)\n",
            "-->  Company ['no', 'med', 'big']\n",
            "--> -->  ('no', 1.0)\n",
            "--> -->  Sailboat ['small', 'big']\n",
            "--> --> -->  ('yes', 1.0)\n",
            "--> --> -->  ('no', 1.0)\n",
            "--> -->  ('yes', 1.0)\n"
          ]
        }
      ],
      "source": [
        "print_tree(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1235,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected EOF while parsing (2980810803.py, line 8)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Input \u001b[1;32mIn [1235]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_lab_1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4ae141d93f6337e9a20a8395b8018e64e99a1e5c84b295f1c46fe5520871454d"
    },
    "kernelspec": {
      "display_name": "'Python Interactive'",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
