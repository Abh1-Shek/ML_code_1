{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jSMWxblgZIUO"
      },
      "outputs": [],
      "source": [
        "# importing packages\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "olU2Ae2vZIUb"
      },
      "outputs": [],
      "source": [
        "# helper function for getting probability from frequency table\n",
        "# this function is used in get_entropy()\n",
        "def get_probability(event_info):\n",
        "  SUM = sum(event_info)\n",
        "  for i in range(len(event_info)):\n",
        "        event_info[i] /= SUM\n",
        "  return event_info\n",
        "\n",
        "\n",
        "# this function gets entropy from frequency table\n",
        "def get_entropy(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  # print('probabilities', probabilities)\n",
        "  entropy = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      entropy += p * math.log(1 / p) / math.log(2)\n",
        "  return entropy\n",
        "\n",
        "# this function gets gini impurity from frequency table\n",
        "def get_gini_impurity(event_info):\n",
        "  probabilities = get_probability(event_info)\n",
        "  # print('probabilities', probabilities)\n",
        "  entropy = 0.0\n",
        "  for p in probabilities:\n",
        "    if p != 0:\n",
        "      entropy += p * (1.0 - p)\n",
        "  return entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z067x_bdZIUe"
      },
      "outputs": [],
      "source": [
        "#this funtion sort table by column\n",
        "def sort_table_by_column(table, col):\n",
        "    return table.sort_values(by = [col]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for importing the dataset as a numpy array\n",
        "dataset1 = pd.read_csv(r\"covid_dataset.csv\")\n",
        "dataset1 = dataset1[dataset1['location'] == 'India']\n",
        "# dataset1 = dataset1.to_numpy()\n",
        "dataset2 = pd.read_csv(r\"changes-visitors-covid.csv\")\n",
        "dataset2 = dataset2[dataset2['Entity'] == 'India']\n",
        "# dataset2 = dataset2.to_numpy()\n",
        "dataset3 = pd.read_csv(r'continuous_attribute_table.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.merge(dataset1, dataset2, on = 'date', how = 'inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X2ZxAmij0lYN"
      },
      "outputs": [],
      "source": [
        "example_dataset = dataset1 = pd.read_csv(r\"example_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfXU0JpnZIUr",
        "outputId": "8028e3e2-181a-4fb8-9586-342564df58c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Outlook Company Sailboat target\n",
            "0   sunny     big    small    yes\n",
            "1   sunny     med    small    yes\n",
            "2   sunny     med      big    yes\n",
            "3   sunny      no    small    yes\n",
            "4   sunny     big      big    yes\n",
            "5   rainy      no    small     no\n",
            "6   rainy     med    small    yes\n",
            "7   rainy     big      big    yes\n",
            "8   rainy      no      big     no\n",
            "9   rainy     med      big     no\n"
          ]
        }
      ],
      "source": [
        "print(example_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "14rFwiubcfP1"
      },
      "outputs": [],
      "source": [
        "def split_dataset_wrt_column(dataset, column_name):\n",
        "  unique_items = dataset[column_name].unique()\n",
        "  for item in unique_items:\n",
        "    yield dataset[dataset[column_name] == item]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eWLqeR9qekVY"
      },
      "outputs": [],
      "source": [
        "class node:\n",
        "  def __init__(self):\n",
        "    self.table = None\n",
        "    self.spliting_feature = None\n",
        "    self.childs = []\n",
        "  def add_child(self, child):\n",
        "    self.childs.append(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WT5mBi9bitUH"
      },
      "outputs": [],
      "source": [
        "def get_count(table, target_column, class_name):\n",
        "  # print(class_name)\n",
        "  # ans =  (table[target_column] == class_name).shape[0]\n",
        "  ans = (table[target_column] == class_name).sum()\n",
        "  # print (ans)\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_GkSt7uXhvQu"
      },
      "outputs": [],
      "source": [
        "def get_entropy_from_table(table, target_column):\n",
        "  unique_classes = table[target_column].unique()\n",
        "  # print(unique_classes)\n",
        "  counts = []\n",
        "  for class_name in unique_classes:\n",
        "    counts.append(get_count(table,target_column, class_name))\n",
        "  # print(\"Count is \", counts)\n",
        "  return get_entropy(counts)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0GeFnIU6gGeC"
      },
      "outputs": [],
      "source": [
        "# this function returns the information gain of the column \"column\" when the target column is \"target_column\" of the table dataset\n",
        "# only for categorical column or attribute\n",
        "def get_information_gain(dataset, column, target_column):\n",
        "  tables = []\n",
        "  size_table = []\n",
        "  overall_size = dataset.shape[0]\n",
        "  for table in split_dataset_wrt_column(dataset, column):\n",
        "    tables.append(table)\n",
        "    size_table.append(table.shape[0])\n",
        "  entropies = []\n",
        "  for table in tables:\n",
        "    print(table)\n",
        "    entropies.append(get_entropy_from_table(table, target_column))\n",
        "  # print(\"entropies=\", entropies)\n",
        "  # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
        "  # print(entropies)\n",
        "  entropy_initial = get_entropy_from_table(dataset, target_column)    # entropy without splitting\n",
        "  # print(\"entropy_intial=\",entropy_initial)\n",
        "  entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(size_table, entropies)])  # entropy after splitting\n",
        "  return (entropy_initial - entropy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "nwdChokGjfGR",
        "outputId": "8cd86971-c26a-4981-bdf6-a8cf0b382329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Outlook Company Sailboat target\n",
            "0   sunny     big    small    yes\n",
            "1   sunny     med    small    yes\n",
            "3   sunny      no    small    yes\n",
            "5   rainy      no    small     no\n",
            "6   rainy     med    small    yes\n",
            "  Outlook Company Sailboat target\n",
            "2   sunny     med      big    yes\n",
            "4   sunny     big      big    yes\n",
            "7   rainy     big      big    yes\n",
            "8   rainy      no      big     no\n",
            "9   rainy     med      big     no\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.034851554559677034"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EWxhZSY7nRQL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Outlook Company Sailboat target\n",
            "0   sunny     big    small    yes\n",
            "1   sunny     med    small    yes\n",
            "3   sunny      no    small    yes\n",
            "5   rainy      no    small     no\n",
            "6   rainy     med    small    yes\n",
            "  Outlook Company Sailboat target\n",
            "2   sunny     med      big    yes\n",
            "4   sunny     big      big    yes\n",
            "7   rainy     big      big    yes\n",
            "8   rainy      no      big     no\n",
            "9   rainy     med      big     no\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.034851554559677034"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_information_gain(example_dataset, 'Sailboat', 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_value_with_min_entropy_wrt_continuous_column(table, column, target_column):\n",
        "    # step 1: sort the table\n",
        "    new_table = sort_table_by_column(table, column)\n",
        "    # print(new_table)\n",
        "    # step 2: get various averages\n",
        "    avg_array = []\n",
        "    length_new_table = len(new_table)\n",
        "    for i in range(length_new_table - 1):\n",
        "        avg_array.append((new_table.at[i,column] + new_table.at[i + 1, column]) / 2)\n",
        "    \n",
        "    # print(avg_array)\n",
        "    # step 3: count before and after averages\n",
        "    IGs = []\n",
        "    for i in range(length_new_table - 1):\n",
        "        table1 = new_table.iloc[:i + 1,:]\n",
        "        table2 = new_table.iloc[i + 1:, :]\n",
        "        # print('Table 1')\n",
        "        # print(table1)\n",
        "        # print('Table 2')\n",
        "        # print(table2)\n",
        "        E1 = get_entropy_from_table(table1, target_column)\n",
        "        E2 = get_entropy_from_table(table2, target_column)\n",
        "        # print('E1=',E1, 'E2=', E2)\n",
        "        E = (len(table1) / len(table)) * E1 + (len(table2) / len(table)) * E2\n",
        "        IG = get_entropy_from_table(new_table, target_column) - E\n",
        "        IGs.append(IG)\n",
        "    print(IGs)\n",
        "    # step 4: calculate the entropy wrt each average\n",
        "    # step 5: determine the best split with most information gain\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.3219280948873625, 0.019973094021975113, 0.41997309402197514, 0.17095059445466876]\n"
          ]
        }
      ],
      "source": [
        "get_value_with_min_entropy_wrt_continuous_column(dataset3, 'Weight', 'Heart_disease')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Heart_disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>225</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>180</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weight Heart_disease\n",
              "0     155            No\n",
              "1     190            No\n",
              "2     220           Yes\n",
              "3     225           Yes\n",
              "4     180           Yes"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_lab_1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4ae141d93f6337e9a20a8395b8018e64e99a1e5c84b295f1c46fe5520871454d"
    },
    "kernelspec": {
      "display_name": "'Python Interactive'",
      "language": "python",
      "name": "52c418bc-bd7d-4061-b6a2-3b59f32782e1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
