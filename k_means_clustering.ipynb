{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "DISTANCE_TYPE = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(dataset, k, no_of_iterations):\n",
    "    indices = np.random.choice(len(dataset), k, replace = False)\n",
    "    # print(indices)\n",
    "    # choose the rows corresponding to indices which is randomly selected\n",
    "    centroids = dataset.iloc[indices, :]\n",
    "    # the below line finds the distance between centroids and all the datapoints\n",
    "    distances = cdist(dataset, centroids, DISTANCE_TYPE)\n",
    "    # print(centroids)\n",
    "    # print(distances)\n",
    "    # structure of distance => [[for one point distace from each centroid], ...]\n",
    "    # the below line assigns each point with the nearest centroid\n",
    "    points = np.array([np.argmin(dist_from_each_centroid) for dist_from_each_centroid in distances])\n",
    "    \n",
    "    # the main algo \n",
    "    for iteration in range(no_of_iterations):\n",
    "        # below array will store the centroids\n",
    "        centroids = []\n",
    "        # finding the new centroid for each of the k clusters\n",
    "        for cluster in range(k):\n",
    "            temp_centroid = dataset[points == cluster].mean(axis = 0)\n",
    "            centroids.append(temp_centroid)\n",
    "        \n",
    "        # new centroids\n",
    "        centroids = np.vstack(centroids)\n",
    "\n",
    "        distances = cdist(dataset, centroids, DISTANCE_TYPE)\n",
    "        points = np.array([np.argmin(dist_from_each_centroid) for dist_from_each_centroid in distances])\n",
    "    \n",
    "    return points, centroids\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5 = pd.read_csv(r'processed_covid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_centroids(dataset, centroids):\n",
    "    distances = cdist(dataset, centroids, DISTANCE_TYPE)\n",
    "    points = np.array([np.argmin(dist_from_each_centroid) for dist_from_each_centroid in distances])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.TREE import DecisionTree # before importing comment DecisionTree() in TREE.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(indexes, x):\n",
    "    indices = []\n",
    "    for i in indexes:\n",
    "        if i == x:\n",
    "            indices.append(True)\n",
    "        else:\n",
    "            indices.append(False)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forest:\n",
    "    def __init__(self, dataset, k, num_of_iterations, TARGET_COLUMN = 'new_cases_classes'):\n",
    "        self.k = k\n",
    "        self.num_of_iterations = num_of_iterations\n",
    "        self.indexes, self.centroids = kmeans(dataset.drop([TARGET_COLUMN], axis = 1), k, num_of_iterations)\n",
    "        self.dataset = dataset\n",
    "        self.DTs = self.create_trees()\n",
    "        self.TARGET_COLUMN = TARGET_COLUMN\n",
    "\n",
    "    def prepare_data_util(self, x):\n",
    "        dataset1 = self.dataset[get_indices(self.indexes, x)]\n",
    "        dataset1.reset_index(drop=True, inplace=True)\n",
    "        return dataset1\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets = []\n",
    "        for i in range(self.k):\n",
    "            datasets.append(self.prepare_data_util(i))\n",
    "        return datasets\n",
    "\n",
    "    def create_trees(self):\n",
    "        DTs = []\n",
    "        datasets = self.prepare_data()\n",
    "        # print(len(datasets))\n",
    "        for dataset in datasets:\n",
    "            DTs.append(DecisionTree(dataset))\n",
    "        return DTs\n",
    "\n",
    "    def calculate_average(self,  all_predictions, centroids):\n",
    "        average_predicted = []\n",
    "        # print(all_predictions)\n",
    "        row, col = len(all_predictions), len(all_predictions[0])\n",
    "        # print(row,col)\n",
    "        for i in range(col):\n",
    "            sum = 0\n",
    "            average_predicted.append(all_predictions[centroids[i]][i])\n",
    "\n",
    "        return(average_predicted)\n",
    "\n",
    "    def predict(self, testing_data):\n",
    "        all_predictions = []\n",
    "        # print(self.DTs)\n",
    "        for DT in self.DTs:\n",
    "            individual_prediction = DT.predict(testing_data)\n",
    "            all_predictions.append(individual_prediction)\n",
    "        # print(all_predictions)\n",
    "        closest_centroids = find_closest_centroids(testing_data.drop([self.TARGET_COLUMN], axis = 1), self.centroids)\n",
    "        final_predictions = self.calculate_average(all_predictions, closest_centroids)\n",
    "        return final_predictions\n",
    "    \n",
    "    def calculate_accuracy(self, testing_data, THRESHOLD_FOR_ACCURACY = 1):\n",
    "        predictions = self.predict(testing_data)\n",
    "        score = 0\n",
    "        # THRESHOLD_FOR_ACCURACY = 1\n",
    "        for i in range(len(testing_data)):\n",
    "            actual = testing_data.at[i, self.TARGET_COLUMN]\n",
    "            predicted = predictions[i]\n",
    "            # print(actual, predicted[0])\n",
    "            score += (abs(actual - predicted[0]) <= THRESHOLD_FOR_ACCURACY)\n",
    "\n",
    "        print(score / len(testing_data) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset5.sample(frac = 0.7)\n",
    "testing_data = dataset5.drop(training_data.index)\n",
    "training_data.reset_index(drop=True, inplace=True)\n",
    "testing_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = Forest(training_data, k = 5, num_of_iterations = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.46808510638297\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.calculate_accuracy(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "52c418bc-bd7d-4061-b6a2-3b59f32782e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
