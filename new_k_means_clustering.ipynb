{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "DISTANCE_TYPE = 'euclidean'\n",
    "DISTANCE_TYPE2 = 'cityblock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(dataset, k, no_of_iterations):\n",
    "    indices = np.random.choice(len(dataset), k, replace = False)\n",
    "    # print(indices)\n",
    "    # choose the rows corresponding to indices which is randomly selected\n",
    "    centroids = dataset.iloc[indices, :]\n",
    "    # the below line finds the distance between centroids and all the datapoints\n",
    "    distances = cdist(dataset, centroids, DISTANCE_TYPE)\n",
    "    # print(centroids)\n",
    "    # print(distances)\n",
    "    # structure of distance => [[for one point mindistance from each centroid], ...]\n",
    "    # the below line assigns each point with the nearest centroid\n",
    "    points = np.array([np.argmin(dist_from_each_centroid) for dist_from_each_centroid in distances])\n",
    "    \n",
    "    # the main algo \n",
    "    for iteration in range(no_of_iterations):\n",
    "        # below array will store the centroids\n",
    "        centroids = []\n",
    "        # finding the new centroid for each of the k clusters\n",
    "        for cluster in range(k):\n",
    "            temp_centroid = dataset[points == cluster].mean(axis = 0)\n",
    "            centroids.append(temp_centroid)\n",
    "        \n",
    "        # new centroids\n",
    "        centroids = np.vstack(centroids)\n",
    "\n",
    "        distances = cdist(dataset, centroids, DISTANCE_TYPE)\n",
    "        points = np.array([np.argmin(dist_from_each_centroid) for dist_from_each_centroid in distances])\n",
    "    \n",
    "    return points, centroids\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5 = pd.read_csv(r'processed_covid_data.csv')  # 'processed_covid_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_centroids(dataset, centroids):\n",
    "    distances = cdist(dataset, centroids, DISTANCE_TYPE)\n",
    "    points = np.array([np.argmin(dist_from_each_centroid) for dist_from_each_centroid in distances])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, condition, children, decisions):\n",
    "        self.condition = condition\n",
    "        self.children = children\n",
    "        self.decisions = decisions\n",
    "        \n",
    "class Leaf:\n",
    "    def __init__(self, leaf_value):\n",
    "        self.leaf_value = leaf_value\n",
    "        self.condition = \"THIS IS A LEAF NODE!!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, dataset = None, THRESHOLD_VALUE = 0.0, THRESHOLD_SIZE = 10, IS_CATEGORICAL = [0,0,0,0,0,0,0,0,0,0,0], TARGET_COLUMN = \"new_cases_classes\", Tree_Type = \"entropy\", THRESHOLD_FOR_ACCURACY = 1):\n",
    "        # this cell contains all the constants please beware\n",
    "        self.THRESHOLD_VALUE = THRESHOLD_VALUE\n",
    "        self.THRESHOLD_SIZE = THRESHOLD_SIZE\n",
    "        self.IS_CATEGORICAL = IS_CATEGORICAL\n",
    "        self.TARGET_COLUMN = TARGET_COLUMN\n",
    "        self.dataset = dataset\n",
    "        self.Tree_Type = Tree_Type\n",
    "        self.THRESHOLD_FOR_ACCURACY = THRESHOLD_FOR_ACCURACY\n",
    "        self.root = self.build_tree(self.dataset)\n",
    "        \n",
    "    \n",
    "    def set_dataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    # helper function for getting probability from frequency table\n",
    "    # this function is used in get_entropy()\n",
    "    def get_probability(self, event_info):\n",
    "        SUM = sum(event_info)\n",
    "        for i in range(len(event_info)):\n",
    "                event_info[i] /= SUM\n",
    "        return event_info\n",
    "\n",
    "\n",
    "    # this function gets entropy from frequency table\n",
    "    def get_entropy(self, event_info):\n",
    "        probabilities = self.get_probability(event_info)\n",
    "        # print('probabilities', probabilities)\n",
    "        entropy = 0.0\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                entropy += p * math.log(1 / p) / math.log(2)\n",
    "        return entropy\n",
    "\n",
    "    # this function gets gini impurity from frequency table\n",
    "    def get_gini_impurity(self, event_info):\n",
    "        probabilities = self.get_probability(event_info)\n",
    "        # print('probabilities', probabilities)\n",
    "        imp = 0.0\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                imp += p * (1.0 - p)\n",
    "        return imp\n",
    "   \n",
    "    #this funtion sort table by column\n",
    "    def sort_table_by_column(self, table, col):\n",
    "        return table.sort_values(by = [col]).reset_index(drop=True)\n",
    "   \n",
    "    def split_dataset_wrt_column(self, dataset, column_name):\n",
    "        unique_items = dataset[column_name].unique()\n",
    "        tables = []\n",
    "        for item in unique_items:\n",
    "            tables.append(dataset[dataset[column_name] == item])\n",
    "        return tables\n",
    "    def get_count(self, table, target_column, class_name):\n",
    "        # print(class_name)\n",
    "        # ans =  (table[target_column] == class_name).shape[0]\n",
    "        ans = (table[target_column] == class_name).sum()\n",
    "        # print (ans)\n",
    "        return ans\n",
    "    def get_entropy_from_table(self, table, target_column):\n",
    "        unique_classes = table[target_column].unique()\n",
    "        # print(unique_classes)\n",
    "        counts = []\n",
    "        for class_name in unique_classes:\n",
    "            counts.append(self.get_count(table,target_column, class_name))\n",
    "        # print(\"Count is \", counts)\n",
    "        if self.Tree_Type == \"entropy\":\n",
    "            return self.get_entropy(counts)\n",
    "        else:\n",
    "            return self.get_gini_impurity(counts)    # write get_gini_impurity if you want to change the parameter to gini imp from entropy\n",
    "    # this function returns the information gain of the column \"column\" when the target column is \"target_column\" of the table dataset\n",
    "    # only for categorical column or attribute\n",
    "    def get_information_gain(self, dataset, column, target_column):\n",
    "        tables = []\n",
    "        size_table = []\n",
    "        overall_size = dataset.shape[0]\n",
    "        for table in self.split_dataset_wrt_column(dataset, column):\n",
    "            tables.append(table)\n",
    "            size_table.append(table.shape[0])\n",
    "        entropies = []\n",
    "        for table in tables:\n",
    "            # print(table)\n",
    "            entropies.append(self.get_entropy_from_table(table, target_column))\n",
    "        # print(\"entropies=\", entropies)\n",
    "        # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
    "        # print(entropies)\n",
    "        entropy_initial = self.get_entropy_from_table(dataset, target_column)    # entropy without splitting\n",
    "        # print(\"entropy_intial=\",entropy_initial)\n",
    "        entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(size_table, entropies)])  # entropy after splitting\n",
    "        return (entropy_initial - entropy)\n",
    "\n",
    "    def max_index(self, arr):\n",
    "        index = 0\n",
    "        mx = arr[0]\n",
    "        for i in range(len(arr)):\n",
    "            if mx < arr[i]:\n",
    "                index = i\n",
    "                mx = arr[i]\n",
    "        return index\n",
    "    \n",
    "\n",
    "    def get_value_with_min_entropy_wrt_continuous_column(self, table, column, target_column):\n",
    "        # step 1: sort the table\n",
    "        new_table = self.sort_table_by_column(table, column)\n",
    "        # print(new_table)\n",
    "        # step 2: get various averages\n",
    "        avg_array = []\n",
    "        length_new_table = len(new_table)\n",
    "        for i in range(length_new_table - 1):\n",
    "            avg_array.append((new_table.at[i,column] + new_table.at[i + 1, column]) / 2)\n",
    "        \n",
    "        # print(avg_array)\n",
    "        # step 3: count before and after averages\n",
    "        IGs = []\n",
    "        parentIG = self.get_entropy_from_table(new_table, target_column)\n",
    "        table1 = None\n",
    "        table2 = None\n",
    "        for i in range(length_new_table - 1):\n",
    "            table1 = new_table.iloc[:i + 1,:]\n",
    "            table2 = new_table.iloc[i + 1:, :]\n",
    "            # print('Table 1')\n",
    "            # print(table1)\n",
    "            # print('Table 2')\n",
    "            # print(table2)\n",
    "            E1 = self.get_entropy_from_table(table1, target_column)\n",
    "            E2 = self.get_entropy_from_table(table2, target_column)\n",
    "            # print('E1=',E1, 'E2=', E2)\n",
    "            E = (len(table1) / len(table)) * E1 + (len(table2) / len(table)) * E2\n",
    "            IG = parentIG - E\n",
    "            IGs.append(IG)\n",
    "        # print(IGs)\n",
    "        # if(len(avg_array) == 0):\n",
    "        #     IGs = [0]\n",
    "        #     avg_array = [1]\n",
    "        index = self.max_index(IGs)\n",
    "        \n",
    "        return avg_array[index], IGs[index]  # split wrt value, IG according to that value\n",
    "        # step 4: calculate the entropy wrt each average\n",
    "        # step 5: determine the best split with most information gain\n",
    "        #This function returns the best column for the split\n",
    "    def get_best_column (self, table, target_column, is_categorical):\n",
    "        values = []\n",
    "        # is_categorical is an array which is true if the data is categorical and false if continuous\n",
    "        IGs = []\n",
    "        for index,column in enumerate(table):\n",
    "            if(column == target_column):\n",
    "                break\n",
    "            # print(column,index)\n",
    "            if(is_categorical[index] == 1):\n",
    "                values.append(None)\n",
    "                IGs.append(self.get_information_gain(table, column, target_column))\n",
    "            else:\n",
    "                #value is the value at which the splitting occurs in the column and IG is the corresponding Info gain\n",
    "                value, IG = self.get_value_with_min_entropy_wrt_continuous_column(table,column,target_column)\n",
    "                values.append(value)\n",
    "                # print(value)\n",
    "                IGs.append(IG)\n",
    "        selected_index = self.max_index(IGs)\n",
    "        if(is_categorical[selected_index]):\n",
    "            return selected_index, table.columns[selected_index], None, IGs[selected_index]\n",
    "        else:\n",
    "            return selected_index, table.columns[selected_index],values[selected_index], IGs[selected_index]\n",
    "    def split_table_wrt_value(self, table,value,column):\n",
    "        table1 = table[table[column] <= value]\n",
    "        table2 = table[table[column] > value]\n",
    "        return table1,table2\n",
    "\n",
    "    # returns the value and probability for the leaf which have maximum probability\n",
    "    def get_value_for_leaf(self, table, target_column):\n",
    "        freq = dict()\n",
    "        unique_classes = table[target_column].unique()\n",
    "        for class_name in unique_classes:\n",
    "            freq[class_name] = 0\n",
    "        for index, row in table.iterrows():\n",
    "            freq[row[target_column]] += 1\n",
    "        mx = 0\n",
    "        value = None\n",
    "        sum_of_freq = 0.0\n",
    "        for class_name, freq_of_class in freq.items():\n",
    "            sum_of_freq += freq_of_class\n",
    "            if mx < freq_of_class:\n",
    "                mx = freq_of_class\n",
    "                value = class_name\n",
    "        return value, mx / sum_of_freq\n",
    "    \n",
    "    def build_tree(self, table, height = 0):\n",
    "        # print(\"height =\", height, \"shape =\", table.shape)\n",
    "        if table.shape[1] == 1 or len(table) <= self.THRESHOLD_SIZE:\n",
    "            return Leaf(self.get_value_for_leaf(table, self.TARGET_COLUMN))\n",
    "        # step1 find the best split\n",
    "        selected_index, column_name, value, best_IG = self.get_best_column(table, self.TARGET_COLUMN, self.IS_CATEGORICAL)\n",
    "        tables = []\n",
    "        decisions = []\n",
    "        condition = None\n",
    "        # categorical value\n",
    "        if value == None:\n",
    "            tables = self.split_dataset_wrt_column(table, column_name)\n",
    "            start_index = 0\n",
    "            for splited_table in tables:\n",
    "                decisions.append(splited_table.iloc[0][column_name])\n",
    "                start_index += len(splited_table)\n",
    "            condition = [None, column_name]\n",
    "        # Continuous Value\n",
    "        else:\n",
    "            table1, table2 = self.split_table_wrt_value(table, value, column_name)\n",
    "            table1 = table1.drop([column_name], axis = 1)\n",
    "            table2 = table2.drop([column_name], axis = 1)\n",
    "            if len(table1) > 0: \n",
    "                tables.append(table1)\n",
    "            if len(table2) > 0:\n",
    "                tables.append(table2)\n",
    "            decisions = [None,None]\n",
    "            condition = [value, column_name]\n",
    "        # put some base condition\n",
    "        if best_IG <= self.THRESHOLD_VALUE or len(table) <= self.THRESHOLD_SIZE:\n",
    "            return Leaf(self.get_value_for_leaf(table, self.TARGET_COLUMN))\n",
    "        # make tree for each child\n",
    "        children = []\n",
    "        for table in tables:\n",
    "            if len(table) > 0:\n",
    "                child = self.build_tree(table, height + 1)\n",
    "                children.append(child)\n",
    "        # return the current node which is already linked to its children so that current node's parent can link current node\n",
    "        return Node(condition, children,decisions)\n",
    "    \n",
    "    def print_tree(self, root, spacing=\"\"):\n",
    "        if isinstance(root, Leaf):\n",
    "            print(spacing, root.leaf_value)\n",
    "            return\n",
    "        print(spacing, root.condition,root.decisions)\n",
    "        for child in root.children:\n",
    "            self.print_tree(child,spacing+\"--> \")\n",
    "    def print_decision_tree(self):\n",
    "        self.print_tree(self.root)\n",
    "    \n",
    "    def find_index(self, arr,x):\n",
    "        for i in range (len(arr)):\n",
    "            if(arr[i] == x):\n",
    "                return i\n",
    "    def predict_util(self, row,root, starting_index = 0):\n",
    "        #base case\n",
    "        # print(row)\n",
    "        if(isinstance(root,Leaf)):\n",
    "            return root.leaf_value\n",
    "        value_to_check = row.at[starting_index, root.condition[1]]\n",
    "        if root.condition[0] != None:\n",
    "            split_value = root.condition[0]\n",
    "            if value_to_check <= split_value:\n",
    "                child_index = 0\n",
    "            else:\n",
    "                child_index = 1\n",
    "        else:\n",
    "            child_index = self.find_index(root.decisions, value_to_check)\n",
    "        # print(value_to_check, root.decisions)\n",
    "        # print(len(root.children))\n",
    "        if (child_index >= len(root.children)):\n",
    "            return -1\n",
    "        return self.predict_util(row, root.children[child_index], starting_index)\n",
    "\n",
    "        \n",
    "    def predict_for_table(self, table, root):\n",
    "        predictions = []\n",
    "        for index, row in table.iterrows():\n",
    "            row = row.to_frame().T\n",
    "            # print(\"index =\", index)\n",
    "            # print('predictions =', predict(row, root, index))\n",
    "            predictions.append(self.predict_util(row, root, index))\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.predict_for_table(data, self.root)\n",
    "    \n",
    "    def calculate_accuracy(self, testing_data):\n",
    "        predictions = self.predict(testing_data)\n",
    "        score = 0\n",
    "        DIFF = 0.0\n",
    "        THRESHOLD_FOR_ACCURACY = 1\n",
    "        for i in range(len(testing_data)):\n",
    "            actual = testing_data.at[i, self.TARGET_COLUMN]\n",
    "            predicted = predictions[i]\n",
    "            # print(actual, predicted)\n",
    "            if self.Tree_Type == 'entropy':\n",
    "                DIFF += abs(actual - predicted[0])\n",
    "                score += (abs(actual - predicted[0]) <= self.THRESHOLD_FOR_ACCURACY)\n",
    "            else:\n",
    "                DIFF += abs(actual - predicted)\n",
    "                score += (abs(actual - predicted) <= self.THRESHOLD_FOR_ACCURACY)\n",
    "\n",
    "        print(score / len(testing_data) * 100)\n",
    "        return predictions, DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(indexes, x):\n",
    "    indices = []\n",
    "    for i in indexes:\n",
    "        if i == x:\n",
    "            indices.append(True)\n",
    "        else:\n",
    "            indices.append(False)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, dataset = None, THRESHOLD_VALUE = 0.0, THRESHOLD_SIZE = 10, IS_CATEGORICAL = [0,0,0,0,0,0,0,0,0,0,0], TARGET_COLUMN = \"new_cases_classes\", Tree_Type = \"entropy\", THRESHOLD_FOR_ACCURACY = 1):\n",
    "        # this cell contains all the constants please beware\n",
    "        self.THRESHOLD_VALUE = THRESHOLD_VALUE\n",
    "        self.THRESHOLD_SIZE = THRESHOLD_SIZE\n",
    "        self.IS_CATEGORICAL = IS_CATEGORICAL\n",
    "        self.TARGET_COLUMN = TARGET_COLUMN\n",
    "        self.dataset = dataset\n",
    "        self.Tree_Type = Tree_Type\n",
    "        self.THRESHOLD_FOR_ACCURACY = THRESHOLD_FOR_ACCURACY\n",
    "        self.root = self.build_tree(self.dataset)\n",
    "        \n",
    "    \n",
    "    def set_dataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    # helper function for getting probability from frequency table\n",
    "    # this function is used in get_entropy()\n",
    "    def get_probability(self, event_info):\n",
    "        SUM = sum(event_info)\n",
    "        for i in range(len(event_info)):\n",
    "                event_info[i] /= SUM\n",
    "        return event_info\n",
    "\n",
    "\n",
    "    # this function gets entropy from frequency table\n",
    "    def get_entropy(self, event_info):\n",
    "        probabilities = self.get_probability(event_info)\n",
    "        # print('probabilities', probabilities)\n",
    "        entropy = 0.0\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                entropy += p * math.log(1 / p) / math.log(2)\n",
    "        return entropy\n",
    "\n",
    "    # this function gets gini impurity from frequency table\n",
    "    def get_gini_impurity(self, event_info):\n",
    "        probabilities = self.get_probability(event_info)\n",
    "        # print('probabilities', probabilities)\n",
    "        imp = 0.0\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                imp += p * (1.0 - p)\n",
    "        return imp\n",
    "   \n",
    "    #this funtion sort table by column\n",
    "    def sort_table_by_column(self, table, col):\n",
    "        return table.sort_values(by = [col]).reset_index(drop=True)\n",
    "   \n",
    "    def split_dataset_wrt_column(self, dataset, column_name):\n",
    "        unique_items = dataset[column_name].unique()\n",
    "        tables = []\n",
    "        for item in unique_items:\n",
    "            tables.append(dataset[dataset[column_name] == item])\n",
    "        return tables\n",
    "    def get_count(self, table, target_column, class_name):\n",
    "        # print(class_name)\n",
    "        # ans =  (table[target_column] == class_name).shape[0]\n",
    "        ans = (table[target_column] == class_name).sum()\n",
    "        # print (ans)\n",
    "        return ans\n",
    "    def get_entropy_from_table(self, table, target_column):\n",
    "        unique_classes = table[target_column].unique()\n",
    "        # print(unique_classes)\n",
    "        counts = []\n",
    "        for class_name in unique_classes:\n",
    "            counts.append(self.get_count(table,target_column, class_name))\n",
    "        # print(\"Count is \", counts)\n",
    "        if self.Tree_Type == \"entropy\":\n",
    "            return self.get_entropy(counts)\n",
    "        else:\n",
    "            return self.get_gini_impurity(counts)    # write get_gini_impurity if you want to change the parameter to gini imp from entropy\n",
    "    # this function returns the information gain of the column \"column\" when the target column is \"target_column\" of the table dataset\n",
    "    # only for categorical column or attribute\n",
    "    def get_information_gain(self, dataset, column, target_column):\n",
    "        tables = []\n",
    "        size_table = []\n",
    "        overall_size = dataset.shape[0]\n",
    "        for table in self.split_dataset_wrt_column(dataset, column):\n",
    "            tables.append(table)\n",
    "            size_table.append(table.shape[0])\n",
    "        entropies = []\n",
    "        for table in tables:\n",
    "            # print(table)\n",
    "            entropies.append(self.get_entropy_from_table(table, target_column))\n",
    "        # print(\"entropies=\", entropies)\n",
    "        # entropies = [get_entropy_from_table(table, target_column) for table in tables]\n",
    "        # print(entropies)\n",
    "        entropy_initial = self.get_entropy_from_table(dataset, target_column)    # entropy without splitting\n",
    "        # print(\"entropy_intial=\",entropy_initial)\n",
    "        entropy = sum([(size / overall_size) * entropyi for size, entropyi in zip(size_table, entropies)])  # entropy after splitting\n",
    "        return (entropy_initial - entropy)\n",
    "\n",
    "    def max_index(self, arr):\n",
    "        index = 0\n",
    "        mx = arr[0]\n",
    "        for i in range(len(arr)):\n",
    "            if mx < arr[i]:\n",
    "                index = i\n",
    "                mx = arr[i]\n",
    "        return index\n",
    "    \n",
    "\n",
    "    def get_value_with_min_entropy_wrt_continuous_column(self, table, column, target_column):\n",
    "        # step 1: sort the table\n",
    "        new_table = self.sort_table_by_column(table, column)\n",
    "        # print(new_table)\n",
    "        # step 2: get various averages\n",
    "        avg_array = []\n",
    "        length_new_table = len(new_table)\n",
    "        for i in range(length_new_table - 1):\n",
    "            avg_array.append((new_table.at[i,column] + new_table.at[i + 1, column]) / 2)\n",
    "        \n",
    "        # print(avg_array)\n",
    "        # step 3: count before and after averages\n",
    "        IGs = []\n",
    "        parentIG = self.get_entropy_from_table(new_table, target_column)\n",
    "        table1 = None\n",
    "        table2 = None\n",
    "        for i in range(length_new_table - 1):\n",
    "            table1 = new_table.iloc[:i + 1,:]\n",
    "            table2 = new_table.iloc[i + 1:, :]\n",
    "            # print('Table 1')\n",
    "            # print(table1)\n",
    "            # print('Table 2')\n",
    "            # print(table2)\n",
    "            E1 = self.get_entropy_from_table(table1, target_column)\n",
    "            E2 = self.get_entropy_from_table(table2, target_column)\n",
    "            # print('E1=',E1, 'E2=', E2)\n",
    "            E = (len(table1) / len(table)) * E1 + (len(table2) / len(table)) * E2\n",
    "            IG = parentIG - E\n",
    "            IGs.append(IG)\n",
    "        # print(IGs)\n",
    "        # if(len(avg_array) == 0):\n",
    "        #     IGs = [0]\n",
    "        #     avg_array = [1]\n",
    "        index = self.max_index(IGs)\n",
    "        \n",
    "        return avg_array[index], IGs[index]  # split wrt value, IG according to that value\n",
    "        # step 4: calculate the entropy wrt each average\n",
    "        # step 5: determine the best split with most information gain\n",
    "        #This function returns the best column for the split\n",
    "    def get_best_column (self, table, target_column, is_categorical):\n",
    "        values = []\n",
    "        # is_categorical is an array which is true if the data is categorical and false if continuous\n",
    "        IGs = []\n",
    "        for index,column in enumerate(table):\n",
    "            if(column == target_column):\n",
    "                break\n",
    "            # print(column,index)\n",
    "            if(is_categorical[index] == 1):\n",
    "                values.append(None)\n",
    "                IGs.append(self.get_information_gain(table, column, target_column))\n",
    "            else:\n",
    "                #value is the value at which the splitting occurs in the column and IG is the corresponding Info gain\n",
    "                value, IG = self.get_value_with_min_entropy_wrt_continuous_column(table,column,target_column)\n",
    "                values.append(value)\n",
    "                # print(value)\n",
    "                IGs.append(IG)\n",
    "        selected_index = self.max_index(IGs)\n",
    "        if(is_categorical[selected_index]):\n",
    "            return selected_index, table.columns[selected_index], None, IGs[selected_index]\n",
    "        else:\n",
    "            return selected_index, table.columns[selected_index],values[selected_index], IGs[selected_index]\n",
    "    def split_table_wrt_value(self, table,value,column):\n",
    "        table1 = table[table[column] <= value]\n",
    "        table2 = table[table[column] > value]\n",
    "        return table1,table2\n",
    "\n",
    "    # returns the value and probability for the leaf which have maximum probability\n",
    "    def get_value_for_leaf(self, table, target_column):\n",
    "        freq = dict()\n",
    "        unique_classes = table[target_column].unique()\n",
    "        for class_name in unique_classes:\n",
    "            freq[class_name] = 0\n",
    "        for index, row in table.iterrows():\n",
    "            freq[row[target_column]] += 1\n",
    "        mx = 0\n",
    "        value = None\n",
    "        sum_of_freq = 0.0\n",
    "        for class_name, freq_of_class in freq.items():\n",
    "            sum_of_freq += freq_of_class\n",
    "            if mx < freq_of_class:\n",
    "                mx = freq_of_class\n",
    "                value = class_name\n",
    "        return value, mx / sum_of_freq\n",
    "    \n",
    "    def build_tree(self, table, height = 0):\n",
    "        # print(\"height =\", height, \"shape =\", table.shape)\n",
    "        if table.shape[1] == 1 or len(table) <= self.THRESHOLD_SIZE:\n",
    "            return Leaf(self.get_value_for_leaf(table, self.TARGET_COLUMN))\n",
    "        # step1 find the best split\n",
    "        selected_index, column_name, value, best_IG = self.get_best_column(table, self.TARGET_COLUMN, self.IS_CATEGORICAL)\n",
    "        tables = []\n",
    "        decisions = []\n",
    "        condition = None\n",
    "        # categorical value\n",
    "        if value == None:\n",
    "            tables = self.split_dataset_wrt_column(table, column_name)\n",
    "            start_index = 0\n",
    "            for splited_table in tables:\n",
    "                decisions.append(splited_table.iloc[0][column_name])\n",
    "                start_index += len(splited_table)\n",
    "            condition = [None, column_name]\n",
    "        # Continuous Value\n",
    "        else:\n",
    "            table1, table2 = self.split_table_wrt_value(table, value, column_name)\n",
    "            table1 = table1.drop([column_name], axis = 1)\n",
    "            table2 = table2.drop([column_name], axis = 1)\n",
    "            if len(table1) > 0: \n",
    "                tables.append(table1)\n",
    "            if len(table2) > 0:\n",
    "                tables.append(table2)\n",
    "            decisions = [None,None]\n",
    "            condition = [value, column_name]\n",
    "        # put some base condition\n",
    "        if best_IG <= self.THRESHOLD_VALUE or len(table) <= self.THRESHOLD_SIZE:\n",
    "            return Leaf(self.get_value_for_leaf(table, self.TARGET_COLUMN))\n",
    "        # make tree for each child\n",
    "        children = []\n",
    "        for table in tables:\n",
    "            if len(table) > 0:\n",
    "                child = self.build_tree(table, height + 1)\n",
    "                children.append(child)\n",
    "        # return the current node which is already linked to its children so that current node's parent can link current node\n",
    "        return Node(condition, children,decisions)\n",
    "    \n",
    "    def print_tree(self, root, spacing=\"\"):\n",
    "        if isinstance(root, Leaf):\n",
    "            print(spacing, root.leaf_value)\n",
    "            return\n",
    "        print(spacing, root.condition,root.decisions)\n",
    "        for child in root.children:\n",
    "            self.print_tree(child,spacing+\"--> \")\n",
    "    def print_decision_tree(self):\n",
    "        self.print_tree(self.root)\n",
    "    \n",
    "    def find_index(self, arr,x):\n",
    "        for i in range (len(arr)):\n",
    "            if(arr[i] == x):\n",
    "                return i\n",
    "    def predict_util(self, row,root, starting_index = 0):\n",
    "        #base case\n",
    "        # print(row)\n",
    "        if(isinstance(root,Leaf)):\n",
    "            return root.leaf_value\n",
    "        value_to_check = row.at[starting_index, root.condition[1]]\n",
    "        if root.condition[0] != None:\n",
    "            split_value = root.condition[0]\n",
    "            if value_to_check <= split_value:\n",
    "                child_index = 0\n",
    "            else:\n",
    "                child_index = 1\n",
    "        else:\n",
    "            child_index = self.find_index(root.decisions, value_to_check)\n",
    "        # print(value_to_check, root.decisions)\n",
    "        # print(len(root.children))\n",
    "        if (child_index >= len(root.children)):\n",
    "            return -1\n",
    "        return self.predict_util(row, root.children[child_index], starting_index)\n",
    "\n",
    "        \n",
    "    def predict_for_table(self, table, root):\n",
    "        predictions = []\n",
    "        for index, row in table.iterrows():\n",
    "            row = row.to_frame().T\n",
    "            # print(\"index =\", index)\n",
    "            # print('predictions =', predict(row, root, index))\n",
    "            predictions.append(self.predict_util(row, root, index))\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.predict_for_table(data, self.root)\n",
    "    \n",
    "    def calculate_accuracy(self, testing_data):\n",
    "        predictions = self.predict(testing_data)\n",
    "        score = 0\n",
    "        DIFF = 0.0\n",
    "        THRESHOLD_FOR_ACCURACY = 1\n",
    "        for i in range(len(testing_data)):\n",
    "            actual = testing_data.at[i, self.TARGET_COLUMN]\n",
    "            predicted = predictions[i]\n",
    "            # print(actual, predicted)\n",
    "            if self.Tree_Type == 'entropy':\n",
    "                DIFF += abs(actual - predicted[0])\n",
    "                score += (abs(actual - predicted[0]) <= self.THRESHOLD_FOR_ACCURACY)\n",
    "            else:\n",
    "                DIFF += abs(actual - predicted)\n",
    "                score += (abs(actual - predicted) <= self.THRESHOLD_FOR_ACCURACY)\n",
    "\n",
    "        print(score / len(testing_data) * 100)\n",
    "        return predictions, DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset5.sample(frac = 0.7)\n",
    "testing_data = dataset5.drop(training_data.index)\n",
    "training_data.reset_index(drop=True, inplace=True)\n",
    "testing_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_ID3A = Forest(training_data, k = 20, num_of_iterations = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.343283582089555\n"
     ]
    }
   ],
   "source": [
    "predictions = forest_ID3A.calculate_accuracy(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_CART = Forest(training_data, k = 20, num_of_iterations = 100, Tree_Type = 'CART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.83582089552239\n"
     ]
    }
   ],
   "source": [
    "predictions = forest_CART.calculate_accuracy(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "# for k in range(3,5):\n",
    "#     print(f\"Running for {k}\")\n",
    "#     forest_ID3A = Forest(training_data, k, num_of_iterations = 100)\n",
    "#     predictions,accuracy = forest_ID3A.calculate_accuracy(testing_data)\n",
    "#     accuracies.append(accuracy)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(accuracies)\n",
    "# plt.xlabel('Values of K')\n",
    "# plt.ylabel('Accuracy in %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = forest_ID3A.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'g', 'b', 'y', 'c']\n",
    "ci = 0\n",
    "for dataset in datasets:\n",
    "    if ci >= 5:\n",
    "        break\n",
    "    plt.scatter(dataset['new_cases_classes'], dataset['workplaces'], c = colors[ci])\n",
    "    ci += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ae141d93f6337e9a20a8395b8018e64e99a1e5c84b295f1c46fe5520871454d"
  },
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
